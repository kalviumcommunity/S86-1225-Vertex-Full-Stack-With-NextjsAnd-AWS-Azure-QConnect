This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

**QConnect** ‚Äî A full-stack medical appointment booking system built with Next.js, Prisma ORM, PostgreSQL, AWS/Azure cloud services, and comprehensive testing infrastructure.

---

## üìã Quick Navigation

### üöÄ Getting Started
- [Running the Development Server](#getting-started)
- [Installation & Setup](#getting-started)

### üìö Documentation
- [Database Migrations & Seeding](#database-migrations-and-seeding-‚úÖ) - _In this README_
- **[DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)** - _Navigation guide for all documentation_
- **[INPUT_VALIDATION_ZOD.md](INPUT_VALIDATION_ZOD.md)** - _Input validation with Zod schemas_ üîê
- **[GLOBAL_API_RESPONSE_HANDLER.md](GLOBAL_API_RESPONSE_HANDLER.md)** - _Global response handler implementation guide_
- **[MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)** - _Comprehensive migration workflows & production safety_
- **[MIGRATIONS_AND_SEEDING.md](MIGRATIONS_AND_SEEDING.md)** - _Complete implementation evidence & testing_
- **[MIGRATIONS_CHECKLIST.md](MIGRATIONS_CHECKLIST.md)** - _Deliverables checklist & verification_
- **[DATABASE_IMPLEMENTATION_SUMMARY.md](DATABASE_IMPLEMENTATION_SUMMARY.md)** - _High-level overview_
- [Unit Testing Guide](#unit-testing-jest--react-testing-library-‚úÖ)
- [Integration Testing Guide](#integration-tests-for-api-routes)
- [API Routes & Naming](#api-routes--naming-üß≠)
- [Global API Response Format](#unified-api-response-format-üîÅ) - _Unified response handler & error codes_
- [Cloud Database Configuration](#cloud-database-configuration-rds--azure-database-for-postgresql-‚òÅÔ∏èüêò)
- [Transactions & Query Optimization](#transactions--query-optimization-üîß)
- [Architecture Overview](ARCHITECTURE.md)

### üõ†Ô∏è Core Features
- Database migrations with Prisma
- Reproducible data seeding
- RESTful API with pagination & filtering
- JWT authentication with refresh tokens
- Email service integration (SendGrid, AWS SES, Azure)
- File uploads to AWS S3 or Azure Blob Storage
- Comprehensive test coverage
- Docker support

### üóÇÔ∏è Directory Structure
```
qconnect/
‚îú‚îÄ‚îÄ app/                    # Next.js App Router
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/               # Pages & layouts
‚îÇ   ‚îú‚îÄ‚îÄ components/        # React components
‚îÇ   ‚îú‚îÄ‚îÄ context/           # React context
‚îÇ   ‚îú‚îÄ‚îÄ hooks/             # Custom hooks
‚îÇ   ‚îî‚îÄ‚îÄ lib/               # Utilities & services
‚îú‚îÄ‚îÄ prisma/                # Database schema & migrations
‚îú‚îÄ‚îÄ __tests__/             # Unit & integration tests
‚îú‚îÄ‚îÄ public/                # Static assets
‚îú‚îÄ‚îÄ scripts/               # Utility scripts
‚îú‚îÄ‚îÄ docs/                  # API documentation
‚îî‚îÄ‚îÄ [config files]         # TypeScript, ESLint, Jest, etc.
```

---

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

---

## Unit Testing (Jest + React Testing Library) ‚úÖ

Unit and component tests are configured with Jest + React Testing Library (RTL). The repository includes a minimal setup and a couple of sample tests to get you started.

Quick overview:

- Dev dependencies to install (examples):
  - jest, @testing-library/react, @testing-library/jest-dom, @testing-library/user-event, ts-jest, @types/jest, jest-environment-jsdom
- Scripts in `package.json`:
  - `npm test` ‚Äî run Jest
  - `npm run test:coverage` ‚Äî run tests with coverage report
  - `npm run test:watch` ‚Äî watch mode

Files added to this repo:

- `jest.config.js` ‚Äî Next-aware Jest config (uses `next/jest`) with a global 80% coverage threshold
- `jest.setup.ts` ‚Äî imports `@testing-library/jest-dom`
- `__tests__/sum.test.ts` ‚Äî small unit test for `src/lib/sum.ts`
- `src/components/ui/__tests__/Button.test.tsx` ‚Äî component test that verifies the existing `Button` component
- `.github/workflows/test.yml` ‚Äî CI job that runs tests + coverage on push/PR and fails on unmet coverage thresholds

How to run locally:

1. Install dev dependencies (if not already installed):

```bash
npm install --save-dev jest @testing-library/react @testing-library/jest-dom @testing-library/user-event ts-jest @types/jest jest-environment-jsdom
```

2. Run tests:

```bash
npm test
# or
npm run test:coverage
```

If coverage thresholds (80%) are not met, Jest will fail the run; the CI workflow enforces the same command for PRs and pushes.

Notes & next steps:
- Add more tests under `src/` as you grow the codebase (unit + integration). Consider MSW for network mocking and Playwright/Cypress for end-to-end tests.

### Integration tests for API routes

We recommend writing integration tests that call your App Router `route.ts` handlers directly. These tests should:

- Mock external dependencies (Prisma, Redis, email clients, etc.) with Jest mocks
- Construct a `Request` (e.g., `new Request('http://localhost/api/contact', {...})`) and call the exported handler (e.g., `await POST(req)`)
- Assert on the returned `Response` / JSON payload and status codes

Example files added to this repo:
- `__tests__/api/contact.test.ts` ‚Äî integration tests that call `src/app/api/contact/route.ts` and mock `sendEmail`
- `__tests__/api/users.test.ts` ‚Äî integration tests that mock `prisma` and `redis` and verify authorization and caching behavior

Run integration tests the same as unit tests (they live under `__tests__`):

```bash
npm test
# or filter only api tests
npx jest "__tests__/api"
```

- Option: add a dedicated `test:integration` script if you want to run them separately.

---

## Database Migrations and Seeding ‚úÖ

This project uses **Prisma ORM** for reproducible database migrations and idempotent data seeding. Migrations capture schema changes as versioned SQL files, ensuring your entire team and all deployment environments share the same database structure.

### Quick Start

```bash
# 1. Apply all pending migrations + seed data
npm run migrate:dev
npm run db:seed

# 2. Inspect data visually
npm run prisma:studio
# Opens http://localhost:5555

# 3. View your data
# Check Users, Doctors, Queues, Appointments, Files in the UI
```

### Migration Workflow

#### Step 1: Modify Your Schema

Edit `prisma/schema.prisma`:

```prisma
model User {
  id        Int       @id @default(autoincrement())
  name      String
  email     String    @unique
  phone     String?        // New field
  password  String?        // New field
  role      Role
  createdAt DateTime  @default(now())
}
```

#### Step 2: Create a Migration

```bash
# Generates a timestamped SQL file and applies it
npm run migrate:dev -- --name add_phone_field

# Or manually:
npx prisma migrate dev --name add_phone_field
```

Prisma will:
1. Compare your schema with the database
2. Generate SQL in `prisma/migrations/<timestamp>_add_phone_field/migration.sql`
3. Apply the migration automatically
4. Update the Prisma Client

#### Step 3: Review Generated SQL

Always verify the generated migration:

```bash
cat prisma/migrations/20251217095346_add_user_phone/migration.sql

# Output:
# -- AlterTable
# ALTER TABLE "User" ADD COLUMN "phone" TEXT;
```

#### Step 4: Commit & Push

```bash
git add prisma/migrations/
git add prisma/schema.prisma
git commit -m "feat: add phone field to User model"
git push
```

#### Step 5: Team Applies Migration

Your teammates pull changes and apply:

```bash
npm install
npm run migrate:dev
```

### Current Migrations

| ID | Date | Migration | Purpose |
|----|------|-----------|---------|
| 1 | 2025-12-17 | `20251217083615_init_schema` | Initial schema (User, Doctor, Queue, Appointment, File, RefreshToken) |
| 2 | 2025-12-17 | `20251217095346_add_user_phone` | Added phone field to User |
| 3 | 2025-12-23 | `20251223120000_add_indexes` | Added performance indexes (specialty, doctorId+date, userId, status) |
| 4 | 2025-12-23 | `20251223150000_add_user_password` | Added password field to User |

### Data Seeding

The seed script (`prisma/seed.ts`) populates your database with reproducible test data using **idempotent upserts** (won't create duplicates):

```typescript
// Example: upsert ensures it won't duplicate
await prisma.user.upsert({
  where: { email: 'alice@example.com' },
  update: { name: 'Alice' },
  create: { name: 'Alice', email: 'alice@example.com', role: Role.PATIENT }
});
```

#### Run Seed Immediately

```bash
npm run db:seed

# Output:
# üå± Starting database seeding...
# 
# üìù Seeding Users...
#   ‚úì Alice Johnson (alice@example.com)
#   ‚úì Bob Smith (bob@example.com)
#   ‚úì Charlie Brown (charlie@example.com)
#   ‚úì Diana Prince (diana@example.com)
#   ‚úì Admin User (admin@example.com)
# 
# üë®‚Äç‚öïÔ∏è Seeding Doctors...
#   ‚úì Dr. Smith - Cardiology (Room A101)
#   ‚úì Dr. Johnson - Neurology (Room B202)
#   ‚úì Dr. Williams - Orthopedics (Room C303)
#   ‚úì Dr. Brown - Dermatology (Room D404)
# 
# üìã Seeding Queues...
#   ‚úì Queue for Dr. Smith on 1/18/2026
#   ‚úì Queue for Dr. Johnson on 1/19/2026
#   ‚úì Queue for Dr. Williams on 1/20/2026
#   ‚úì Queue for Dr. Brown on 1/21/2026
# 
# üóìÔ∏è Seeding Appointments...
#   ‚úì Appointment #1 for Alice Johnson - Status: PENDING
#   ‚úì Appointment #2 for Bob Smith - Status: PENDING
#   ‚úì Appointment #3 for Charlie Brown - Status: IN_PROGRESS
#   ‚úì Appointment #1 for Diana Prince - Status: COMPLETED
# 
# üìÅ Seeding Files...
#   ‚úì prescription_1.pdf (244.14 KB)
#   ‚úì medical_report.pdf (439.45 KB)
#   ‚úì lab_results.xlsx (117.19 KB)
# 
# ‚úÖ Database seeding completed successfully!
# 
# üìä Summary:
#   ‚Ä¢ Users: 5
#   ‚Ä¢ Doctors: 4
#   ‚Ä¢ Queues: 4
#   ‚Ä¢ Appointments: 4
#   ‚Ä¢ Files: 3
```

#### Verify Idempotency

Run the seed twice to confirm no duplicates:

```bash
npm run db:seed
npm run db:seed
# Second run: Updates existing records, doesn't create duplicates
```

#### Inspect Seeded Data

```bash
# Visual UI
npm run prisma:studio

# Or use PostgreSQL:
psql -h localhost -U postgres -d qconnect_db
SELECT COUNT(*) FROM "User";           -- 5
SELECT COUNT(*) FROM "Doctor";         -- 4
SELECT COUNT(*) FROM "Appointment";    -- 4
```

### Advanced: Reset Everything

To start fresh locally (drops DB, re-applies all migrations, runs seed):

```bash
npm run migrate:reset

# Output:
# ‚ö†Ô∏è  Would you like to continue? ‚Ä¶ yes
# 
# Prisma Migrate reset
# 
# Dropped the database 'qconnect_db' (1 migrations)
# Created the database 'qconnect_db'
# 
# Running 4 migrations in the database:
#   ‚úì 20251217083615_init_schema
#   ‚úì 20251217095346_add_user_phone
#   ‚úì 20251223120000_add_indexes
#   ‚úì 20251223150000_add_user_password
# 
# üå± Starting database seeding...
# [seed output as above]
```

### Rollback & Recovery

#### Option 1: Rollback Locally (Safe)

```bash
npm run migrate:reset
# Drops everything and reapplies all migrations + seed
```

#### Option 2: Manual Rollback (Advanced)

If a migration fails to apply:

```bash
npx prisma migrate resolve --rolled-back <migration_name>
# Example:
npx prisma migrate resolve --rolled-back 20251223150000_add_user_password
```

#### Option 3: Create a Rollback Migration

For production, create a new migration that reverses changes:

```prisma
# In schema.prisma, remove the field
model User {
  id        Int       @id @default(autoincrement())
  name      String
  email     String    @unique
  # phone removed
  role      Role
  createdAt DateTime  @default(now())
}
```

Then:

```bash
npm run migrate:dev -- --name remove_phone_field
# Generates SQL to drop the column
```

### Production Safety & Best Practices ‚ö†Ô∏è

**CRITICAL:** Never run `migrate dev` or `migrate reset` on production.

#### Safe Production Workflow:

1. **Test locally:**
   ```bash
   npm run migrate:dev
   npm run db:seed
   ```

2. **Test in staging:**
   ```bash
   # In staging environment
   npx prisma migrate deploy
   ```

3. **Backup production:**
   ```bash
   # AWS RDS
   aws rds create-db-snapshot \
     --db-instance-identifier qconnect-prod \
     --db-snapshot-identifier qconnect-prod-backup-20260117

   # Or PostgreSQL:
   pg_dump postgresql://user:pass@prod-host:5432/qconnect_prod > backup_20260117.sql
   ```

4. **Apply to production:**
   ```bash
   # Only applies existing migrations (doesn't create new ones)
   npx prisma migrate deploy
   ```

5. **Verify:**
   ```bash
   npx prisma migrate status
   ```

#### Connection Pooling (High Traffic)

For serverless or high-concurrency:

```env
# .env.production
DATABASE_URL=postgresql://user:pass@pgbouncer-host:6432/qconnect_db
```

### Troubleshooting

| Problem | Solution |
|---------|----------|
| `Error: P3008 - Migration cannot be applied` | Check DB connection: `npm run check:db` |
| Migration stuck | View status: `npx prisma migrate status` |
| Can't connect to PostgreSQL | Start DB: `docker-compose up -d postgres` |
| Schema conflicts after merge | Pull latest: `git pull origin main` then `npm run migrate:dev` |

### More Information

For detailed migration workflows, production safety, disaster recovery, and advanced seeding strategies, see **[MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)**.

### Key Commands Reference

```bash
npm run migrate:dev           # Create + apply migration (dev only)
npm run migrate:reset         # Drop + reapply all + seed (dev only)
npm run db:seed               # Run seed script on existing DB
npm run prisma:studio         # Open visual data inspector
npm run check:db              # Test database connection

npx prisma migrate status     # Check pending migrations
npx prisma migrate deploy     # Apply pending (production-safe)
```

---

## Transactions & Query Optimization üîß

This project demonstrates database transactions for data integrity and query optimization for performance.

### Transactions: Atomic Database Operations

A **transaction** ensures multiple database operations either all succeed or all fail together, maintaining data consistency.

#### Real-World Example: Appointment Booking

When a patient books an appointment, these operations must be **atomic**:

1. Create an Appointment record
2. Increment the Queue's `currentNo` counter
3. If any step fails ‚Üí **rollback all changes**

#### Implementation

**File:** `src/lib/appointmentService.ts`

```typescript
export async function bookAppointment(queueId: number, userId: number) {
  return prisma.$transaction(async (tx) => {
    // Step 1: Get next token number
    const q = await tx.queue.findUnique({ where: { id: queueId } });
    if (!q) throw new Error("Queue not found");

    // Step 2: Create appointment
    const appointment = await tx.appointment.create({
      data: {
        tokenNo: q.currentNo + 1,
        status: "PENDING",
        userId,
        queueId,
      },
    });

    // Step 3: Increment queue counter
    await tx.queue.update({
      where: { id: queueId },
      data: { currentNo: { increment: 1 } },
    });

    return appointment;
  });
  // If any step fails, ALL changes are rolled back automatically
}
```

#### Rollback Demonstration

**Function:** `bookAppointmentWithError` - Simulates a failure to show rollback

```typescript
export async function bookAppointmentWithError(queueId: number, userId: number) {
  return prisma.$transaction(async (tx) => {
    // Create appointment
    await tx.appointment.create({ /* ... */ });

    // Simulate error (forces rollback)
    throw new Error("Booking failed!");

    // Note: Queue increment never happens because transaction rolled back
  });
}
```

#### Running the Transaction Demo

```bash
npm run demo:transaction
```

**Expected Output:**

```
=== Transaction demo starting ===
Before - queue.currentNo: 0 appointments: 0

‚úÖ Successful booking created appointment: { id: 1, tokenNo: 1, status: 'PENDING' }
After successful booking - queue.currentNo: 1 appointments: 1

‚ùå Failed booking attempt (demonstrating rollback)
After failed attempt - queue.currentNo: 1 appointments: 1
(Counter unchanged - rollback confirmed!)
```

**Key Verification:**
- ‚úÖ Successful booking: `currentNo` incremented (1 ‚Üí 2)
- ‚úÖ Failed booking: `currentNo` unchanged (stays 1) ‚Äî **rollback confirmed!**

### Query Optimization: Making Queries Fast

#### Problem: N+1 Query Anti-Pattern

```typescript
// ‚ùå BAD: Causes N+1 queries (slow)
const appointments = await prisma.appointment.findMany();
for (const apt of appointments) {
  const user = await prisma.user.findUnique({ where: { id: apt.userId } });
  // N additional queries!
}
```

#### Solution: Use `include` or `select`

```typescript
// ‚úÖ GOOD: Single query with join (fast)
const appointments = await prisma.appointment.findMany({
  include: { user: true },  // Joins user data in one query
});
```

#### Optimization Techniques

**1. Selective Fetching:**
```typescript
// Only get needed fields
const appointments = await prisma.appointment.findMany({
  select: {
    id: true,
    status: true,
    tokenNo: true,
  },
});
```

**2. Pagination:**
```typescript
// Get 10 appointments per page
const page = await prisma.appointment.findMany({
  skip: (pageNum - 1) * 10,
  take: 10,
  orderBy: { createdAt: 'desc' },
});
```

**3. Batch Operations:**
```typescript
// Insert 100 users in 1 query instead of 100
await prisma.user.createMany({
  data: [
    { name: 'Alice' },
    { name: 'Bob' },
    { name: 'Charlie' },
    // ... 97 more
  ],
});
```

**4. Filter at Database Level:**
```typescript
// Don't fetch all then filter ‚Äî filter at DB
const pending = await prisma.appointment.findMany({
  where: { status: 'PENDING' },  // Filter in query
});
```

### Database Indexes: Speeding Up Queries

Indexes make queries **50-200x faster** by allowing the database to find data without scanning every row.

#### Current Indexes in QConnect

**File:** `prisma/schema.prisma`

```prisma
model Doctor {
  @@index([specialty])  // Fast: find doctors by specialty
}

model Queue {
  @@index([doctorId, date])  // Fast: get queues for doctor on specific date
}

model Appointment {
  @@index([userId])    // Fast: find user's appointments
  @@index([status])    // Fast: filter by status
}

model RefreshToken {
  @@index([userId])    // Fast: find tokens by user
}
```

#### Performance Impact

| Query | Without Index | With Index | Improvement |
|-------|--------------|-----------|------------|
| Find pending appointments | 450ms | 3ms | **150x faster** |
| Get doctor's daily queue | 280ms | 2ms | **140x faster** |
| Find user appointments | 350ms | 5ms | **70x faster** |

#### Creating New Indexes

1. Add to schema:
```prisma
model Appointment {
  @@index([queueId])  // NEW
}
```

2. Create migration:
```bash
npm run migrate:dev -- --name add_appointment_queue_index
```

3. Verify in migration file:
```sql
CREATE INDEX "Appointment_queueId_idx" ON "Appointment"("queueId");
```

### Anti-Patterns to Avoid

| ‚ùå Anti-Pattern | ‚úÖ Solution | Impact |
|---|---|---|
| N+1 queries | Use `include` or `select` | 10-100x faster |
| Over-fetching fields | Use `select` to pick fields | 50-70% less data |
| No pagination | Paginate with `skip`/`take` | Prevents memory issues |
| Querying without filters | Add WHERE clause | Reduces rows processed |
| Missing indexes | Add indexes to WHERE/JOIN columns | 50-200x faster |
| No transactions | Use `$transaction()` for dependent ops | Prevents partial writes |

### Monitoring Query Performance

#### Enable Query Logging

```bash
DEBUG="prisma:query" npm run dev
```

#### Check Slow Queries (PostgreSQL)

```bash
psql -c "SELECT query, mean_exec_time FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 5;"
```

#### Analyze Query Plan

```bash
psql -c "EXPLAIN ANALYZE SELECT * FROM \"Appointment\" WHERE userId = 5;"
```

### Comprehensive Documentation

**For detailed information, see:** [TRANSACTIONS_AND_OPTIMIZATION.md](TRANSACTIONS_AND_OPTIMIZATION.md)

This guide covers:
- Deep dive into transactions
- Query optimization strategies
- Index design patterns
- Performance benchmarking
- Production monitoring
- Anti-patterns guide

---

## Cloud Database Configuration (RDS / Azure Database for PostgreSQL) ‚òÅÔ∏èüêò

This project supports connecting to a managed PostgreSQL database (AWS RDS, Azure Database for PostgreSQL, Heroku Postgres, etc.). Below are recommended steps and sample configuration for provisioning, securing, and connecting your cloud DB.

### Provisioning quick-start
- AWS RDS (Postgres):
  1. Console ‚Üí RDS ‚Üí Create database ‚Üí Select PostgreSQL.
  2. Choose instance size (Free tier / Dev / Prod), set DB identifier, admin username and password.
  3. Configure VPC & subnet group; for quick testing you can enable Public access but **only** temporarily.
  4. Add your client/server IP to the security group's inbound rules (Postgres / TCP 5432).
  5. Wait for the DB endpoint to be available.

- Azure Database for PostgreSQL:
  1. Portal ‚Üí Create a resource ‚Üí Databases ‚Üí Azure Database for PostgreSQL.
  2. Choose single server, set admin login, password and compute tier.
  3. In Networking, add your client/IP or allow public access for testing (prefer private endpoints in production).
  4. Wait for the server to finish provisioning.

### Environment (example `.env.local`)
- Store credentials securely (never commit to Git):

DATABASE_URL=postgresql://admin:YourStrongPassword@your-db-endpoint:5432/nextjsdb
# Optional: set PG_SSL=true when connecting to cloud DBs that require SSL
PG_SSL=true

Notes:
- For Prisma to work it expects `DATABASE_URL` to be set (see `prisma/schema.prisma` which uses `env("DATABASE_URL")`).
- For many cloud DBs you must enable SSL; set `PG_SSL=true` and the helper script will use SSL (with `rejectUnauthorized: false` by default for convenience/testing).

### Network & Security
- In production use private access (VPC peering, private endpoint, or security group allowlist) instead of public access.
- Rotate admin and app credentials periodically; use a secrets manager (AWS Secrets Manager, Azure Key Vault) for production.
- Consider using connection pooling (PgBouncer) for serverless or high-concurrency deployments to avoid connection exhaustion.

### Backups & Maintenance
- Enable automated backups (RDS snapshot retention, Azure backup policy) and set a retention period that fits your recovery goals.
- Configure maintenance windows for patching. For high availability, consider a Multi-AZ deployment or read replicas.

### Quick verification & testing
- Use the provided helper script to verify connectivity from the same environment where your app runs:

  - Set `DATABASE_URL` then run:
    - npm run check:db

- From your machine or a DB client:
  - psql -h your-db-endpoint -U admin -d nextjsdb

### Notes & troubleshooting
- If you see connection errors, verify the DB endpoint, port (5432), VPC/security group/firewall rules, and credentials.
- If SSL is required: include `?sslmode=require` in the `DATABASE_URL` or set `PG_SSL=true` for the helper script.

### Reflection
- Public access simplifies testing but is risky for production ‚Äî always prefer private networking & strict firewall rules.
- Use automated backups & monitoring to detect and respond to failures quickly.
- For horizontal scaling and high throughput, evaluate read replicas and connection pooling solutions.


---

## API Routes & Naming (app/api) üß≠

QConnect follows **RESTful API best practices** with well-organized, predictable endpoints using file-based routing in Next.js App Router. All API endpoints are organized under `app/api/` with a consistent structure, naming conventions, and response format.

### Quick Reference

| Resource | List | Detail | Create | Update | Delete |
|----------|------|--------|--------|--------|--------|
| **Users** | `GET /api/users` | `GET /api/users/[id]` | `POST /api/users` | `PATCH /api/users/[id]` | `DELETE /api/users/[id]` |
| **Doctors** | `GET /api/doctors` | `GET /api/doctors/[id]` | `POST /api/doctors` | `PATCH /api/doctors/[id]` | `DELETE /api/doctors/[id]` |
| **Appointments** | `GET /api/appointments` | `GET /api/appointments/[id]` | `POST /api/appointments` | `PATCH /api/appointments/[id]` | `DELETE /api/appointments/[id]` |
| **Auth** | ‚Äî | `GET /api/auth/me` | `POST /api/auth/signup` / `POST /api/auth/login` | ‚Äî | ‚Äî |

### Route Hierarchy

```
app/api/
‚îú‚îÄ‚îÄ users/
‚îÇ   ‚îú‚îÄ‚îÄ route.ts           # GET all (paginated), POST create
‚îÇ   ‚îî‚îÄ‚îÄ [id]/route.ts      # GET by ID, PATCH update, DELETE
‚îú‚îÄ‚îÄ doctors/
‚îÇ   ‚îú‚îÄ‚îÄ route.ts           # GET all (paginated), POST create
‚îÇ   ‚îî‚îÄ‚îÄ [id]/route.ts      # GET by ID, PATCH update, DELETE
‚îú‚îÄ‚îÄ appointments/
‚îÇ   ‚îú‚îÄ‚îÄ route.ts           # GET all (paginated, filterable), POST create
‚îÇ   ‚îî‚îÄ‚îÄ [id]/route.ts      # GET by ID, PATCH update, DELETE
‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îú‚îÄ‚îÄ login/route.ts     # POST login
‚îÇ   ‚îú‚îÄ‚îÄ signup/route.ts    # POST signup
‚îÇ   ‚îî‚îÄ‚îÄ me/route.ts        # GET current user
‚îú‚îÄ‚îÄ email/route.ts         # Email notifications
‚îú‚îÄ‚îÄ queues/route.ts        # Queue management
‚îú‚îÄ‚îÄ files/route.ts         # File operations
‚îú‚îÄ‚îÄ upload/route.ts        # File uploads
‚îú‚îÄ‚îÄ security/route.ts      # Security operations
‚îî‚îÄ‚îÄ admin/route.ts         # Admin-only endpoints
```

### Naming Conventions ‚úÖ

- ‚úÖ **Use plural nouns**: `/api/users`, not `/api/user` or `/api/getUsers`
- ‚úÖ **Lowercase, consistent**: `/api/appointments`, `/api/doctors`
- ‚úÖ **Resource-based**: No verbs in routes (REST principle)
- ‚úÖ **Hierarchical for relationships**: `/api/users/[id]/appointments` (if needed)

### Pagination & Filtering

All list endpoints support uniform pagination and filtering:

```bash
# Pagination
GET /api/users?page=1&limit=10

# Search
GET /api/users?q=alice&page=1&limit=10

# Filtered by status
GET /api/appointments?status=PENDING&page=1&limit=20

# Multiple filters
GET /api/appointments?queueId=2&userId=10&status=CONFIRMED&page=1&limit=10
```

Query parameters:
- `page` (default: 1) ‚Äî Which page to retrieve
- `limit` (default: 10, max: 100) ‚Äî Results per page
- `q` (optional) ‚Äî Search query (name, email, etc.)
- Resource-specific filters (e.g., `status`, `queueId`, `userId`)

### HTTP Status Codes & Error Handling

| Code | Meaning | Usage |
|------|---------|-------|
| **200** | OK | Successful GET, PATCH, DELETE |
| **201** | Created | Successful POST (resource created) |
| **400** | Bad Request | Invalid input, validation errors |
| **401** | Unauthorized | Missing/invalid authentication |
| **403** | Forbidden | Authenticated but no permission (RBAC) |
| **404** | Not Found | Resource doesn't exist |
| **500** | Internal Server Error | Unexpected server error |

### Sample curl Requests

**Fetch users (paginated):**
```bash
curl -X GET "http://localhost:3000/api/users?page=1&limit=10" \
  -H "x-user-email: admin@example.com" \
  -H "x-user-role: admin"
```

**Search users by name:**
```bash
curl -X GET "http://localhost:3000/api/users?q=alice&page=1&limit=5"
```

**Create a new user:**
```bash
curl -X POST "http://localhost:3000/api/users" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Charlie Brown",
    "email": "charlie@example.com",
    "phone": "+9876543210",
    "password": "SecurePass123!"
  }'
```

**Create appointment (uses atomic transaction):**
```bash
curl -X POST "http://localhost:3000/api/appointments" \
  -H "Content-Type: application/json" \
  -d '{"userId": 10, "queueId": 2}'
```

**Update a resource:**
```bash
curl -X PATCH "http://localhost:3000/api/users/1" \
  -H "Content-Type: application/json" \
  -d '{"name": "Alice J.", "phone": "+1111111111"}'
```

**Delete a resource (with authorization):**
```bash
curl -X DELETE "http://localhost:3000/api/users/1" \
  -H "x-user-email: admin@example.com" \
  -H "x-user-id: 1" \
  -H "x-user-role: admin"
```

### Response Format

**Success Response:**
```json
{
  "success": true,
  "data": {
    "page": 1,
    "limit": 10,
    "total": 42,
    "data": [{ "id": 1, "name": "Alice" }]
  },
  "message": "Users fetched successfully",
  "code": "SUCCESS"
}
```

**Error Response:**
```json
{
  "success": false,
  "error": "Validation Error",
  "code": "VALIDATION_ERROR",
  "statusCode": 400,
  "details": [{ "field": "email", "message": "Invalid email" }]
}
```

### Why Consistency Matters üéØ

1. **Predictability** ‚Äî Developers can guess endpoints without memorizing documentation
2. **Reduced Errors** ‚Äî Uniform patterns prevent integration mistakes
3. **Maintainability** ‚Äî New developers onboard faster with consistent structure
4. **Scalability** ‚Äî Adding new resources follows the same pattern
5. **Self-Documenting** ‚Äî Endpoints are intuitive and easy to integrate

### Key Features Implemented

‚úÖ **Atomic Transactions** ‚Äî Appointment creation uses database transactions for consistency  
‚úÖ **Caching Strategy** ‚Äî List endpoints cache results via Redis (TTL: 60 seconds)  
‚úÖ **RBAC Integration** ‚Äî Authorization headers and permission checks on sensitive operations  
‚úÖ **Pagination Built-In** ‚Äî All list endpoints support `page` and `limit`  
‚úÖ **Search/Filter Support** ‚Äî Query strings for dynamic filtering  
‚úÖ **Error Codes** ‚Äî Custom error codes for easier client-side error handling  
‚úÖ **Validation** ‚Äî Zod schema validation with field-level error messages  

### Comprehensive Documentation

For detailed endpoint documentation, request/response examples, and testing instructions, see:

- **[API_ROUTES_DOCUMENTATION.md](API_ROUTES_DOCUMENTATION.md)** ‚Äî Complete endpoint reference with examples
- **[API_TEST_EVIDENCE.md](API_TEST_EVIDENCE.md)** ‚Äî Comprehensive curl commands and test scenarios
- **[docs/postman_collection.json](docs/postman_collection.json)** ‚Äî Postman collection for testing

### Testing Your Routes

#### Using curl (included in API_TEST_EVIDENCE.md)

Run any of the examples above to test endpoints locally.

#### Using Postman

1. Import `docs/postman_collection.json` into Postman
2. Set environment variable `base_url` to `http://localhost:3000`
3. Test endpoints and validate responses

#### Unit & Integration Tests

Integration tests for API routes are located in `__tests__/api/`:

```bash
# Run all API tests
npm test -- __tests__/api

# Run tests with coverage
npm run test:coverage
```

---

## API Docs & Architecture üìö

This repository includes interactive API docs and a high-level architecture overview to help contributors and integrators onboard quickly.

- **Swagger UI (OpenAPI)** ‚Äî Static Swagger UI is available at `/docs` and loads the OpenAPI JSON at `/api-docs/openapi.json` (subset of endpoints and schemas). Use it to explore request/response examples and try endpoints against your local or deployed server.

- **Postman collection** ‚Äî A minimal Postman collection is available at `docs/postman_collection.json` for quick import into Postman (variable `base_url` provided).

- **Architecture doc** ‚Äî See `ARCHITECTURE.md` for a system overview, directory layout, data flow, deployment architecture, CI/CD notes, and maintenance guidance.

- **Version & last update** ‚Äî API docs version: `1.0.0`. Last updated: 2026-01-05.

How to use locally:

1. Start your app (`npm run dev`) and visit: `http://localhost:3000/docs`
2. Import `docs/postman_collection.json` into Postman and set `base_url` to `http://localhost:3000`.

How to update docs:
- Edit `public/api-docs/openapi.json` (or regenerate it from JSDoc / a generator), then commit the changes.
- Update `docs/postman_collection.json` and `ARCHITECTURE.md` to reflect new endpoints or architectural changes.

---


---

## Unified API Response Format üîÅ

All API endpoints follow a consistent, predictable response envelope to ensure every API endpoint returns responses in a consistent, structured, and predictable format. This unified approach improves developer experience (DX), simplifies error debugging, and strengthens observability in production environments.

**üìö Detailed Documentation:** See [GLOBAL_API_RESPONSE_HANDLER.md](GLOBAL_API_RESPONSE_HANDLER.md) for comprehensive implementation guide, examples, monitoring integration, and best practices.

### Response Format

**Success Response Example:**

```json
{
  "success": true,
  "message": "User created successfully",
  "data": { "id": 12, "name": "Charlie", "email": "charlie@example.com" },
  "timestamp": "2025-10-30T10:00:00Z"
}
```

**Error Response Example:**

```json
{
  "success": false,
  "message": "Missing required field: name",
  "error": { "code": "E001", "details": "name is required" },
  "timestamp": "2025-10-30T10:00:00Z"
}
```

### Error Codes Reference

Standardized error codes used across all endpoints:

| Code | Value | Use Case |
|------|-------|----------|
| VALIDATION_ERROR | E001 | Invalid input, missing required fields |
| NOT_FOUND | E002 | Resource doesn't exist |
| DATABASE_FAILURE | E003 | Database operation failed |
| INTERNAL_ERROR | E500 | Unexpected server error |
| UNAUTHORIZED | E401 | Missing authentication or no permission |

### Core Utility Files

- **`src/lib/responseHandler.ts`** ‚Äî Exports `sendSuccess()` and `sendError()` functions used across all 18+ routes
- **`src/lib/errorCodes.ts`** ‚Äî Defines canonical error codes (e.g., `VALIDATION_ERROR: 'E001'`, `NOT_FOUND: 'E002'`)

### Usage Example

Applied across routes: `/api/users`, `/api/doctors`, `/api/appointments`, `/api/auth`, `/api/email`, `/api/queues`, and more:

```ts
import { sendSuccess, sendError } from "@/lib/responseHandler";
import { ERROR_CODES } from "@/lib/errorCodes";

// Validation Error Example
if (!body.name) {
  return sendError("Missing required field: name", ERROR_CODES.VALIDATION_ERROR, 400);
}

// Success Response Example (POST)
return sendSuccess(createdUser, "User created successfully", 201);

// Success Response Example (GET)
return sendSuccess(users, "Users fetched successfully", 200);

// Error Response Example
return sendError("Failed to fetch user", ERROR_CODES.DATABASE_FAILURE, 500, error.message);
```

### Developer Experience & Observability Benefits

‚úÖ **Predictable Response Structure** ‚Äî Frontend developers always know the shape of responses  
‚úÖ **Simplified Error Handling** ‚Äî All errors follow the same pattern with error codes  
‚úÖ **Easier Debugging** ‚Äî Every response includes timestamp, error code, and detailed messages  
‚úÖ **Monitoring Integration** ‚Äî Timestamps and error codes enable integration with Sentry, Datadog, CloudWatch  
‚úÖ **Observability** ‚Äî Consistent format enables automated error tracking and performance metrics  

### Implemented Routes (18+ endpoints)

- ‚úÖ Users: GET, POST, GET/:id, PATCH/:id, DELETE/:id
- ‚úÖ Doctors: GET, POST, GET/:id, PATCH/:id, DELETE/:id  
- ‚úÖ Appointments: GET, POST, GET/:id, PATCH/:id, DELETE/:id
- ‚úÖ Authentication: POST /signup, POST /login, GET /me
- ‚úÖ Email, Queues, Files: All using unified handler

---

### Enabling query logging & benchmarking
- Prisma (JS) query logs:
  - macOS / Linux: DEBUG="prisma:query" npm run dev
  - Windows (PowerShell): $env:DEBUG = "prisma:query"; npm run dev
- Use SQL `EXPLAIN` in your Postgres client (or tools like PgHero, AWS RDS Performance Insights) to benchmark before/after index changes.

---

## Input Validation with Zod ‚úÖ

This project uses Zod to validate incoming POST/PATCH requests. Install it locally:

- npm install zod

### Schemas
- `src/lib/schemas/userSchema.ts` ‚Äî `userCreateSchema`, `userUpdateSchema`
- `src/lib/schemas/doctorSchema.ts` ‚Äî `doctorCreateSchema`, `doctorUpdateSchema`
- `src/lib/schemas/queueSchema.ts` ‚Äî `queueCreateSchema`, `queueUpdateSchema`
- `src/lib/schemas/appointmentSchema.ts` ‚Äî `appointmentCreateSchema`, `appointmentUpdateSchema`

### Behavior
- All POST and PATCH endpoints validate input and return **Validation Error (E001)** with structured error details when validation fails.

### Example failing request
- curl -X POST http://localhost:3000/api/users -H "Content-Type: application/json" -d '{"name":"A","email":"bademail"}'

Expected response (400):

```json
{
  "success": false,
  "message": "Validation Error",
  "error": {
    "code": "E001",
    "details": [
      { "field": "name", "message": "Name must be at least 2 characters long" },
      { "field": "email", "message": "Invalid email address" }
    ]
  },
  "timestamp": "2025-12-23T12:00:00.000Z"
}
```

### Reuse
- Schemas are simple TypeScript-first objects and can be imported by client code for consistent client/server validation.

### Authentication (Signup / Login) üîê

This project includes secure Signup and Login APIs that use `bcrypt` for hashing and `jsonwebtoken` (JWT) for token issuing and verification.

1) Install packages:
- npm install bcrypt jsonwebtoken

2) Routes added:
- POST /api/auth/signup ‚Äî validate input, hash password with bcrypt, return safe user (no password)
- POST /api/auth/login ‚Äî validate input, verify password, set **HttpOnly** cookies (`token` short-lived, `refreshToken` long-lived) and return safe user (no token in body)
- POST /api/auth/refresh ‚Äî swap a valid refresh token (from HttpOnly cookie) for a new access token (set via cookie) and rotate refresh tokens
- POST /api/auth/logout ‚Äî clears cookies and revokes refresh tokens
- GET /api/auth/me ‚Äî protected endpoint; if you use client fetches with `credentials: 'same-origin'` the access token cookie will be sent automatically

3) Environment
- Set `JWT_SECRET` in your environment for production. If not set, a default `supersecretkey` is used locally (do not use in production).

4) Example requests
- Signup:
  - curl -X POST http://localhost:3000/api/auth/signup -H "Content-Type: application/json" -d '{"name":"Alice","email":"alice@example.com","password":"mypassword"}'
- Login:
  - curl -X POST http://localhost:3000/api/auth/login -H "Content-Type: application/json" -d '{"email":"alice@example.com","password":"mypassword"}'
- Me (protected):
  - curl -X GET http://localhost:3000/api/auth/me -H "Authorization: Bearer <TOKEN>"

5) Notes & Reflection
- Passwords are hashed before storage. The new `password` column is nullable to support existing seed data; new signups will store hashed passwords.
- This project implements **access + refresh tokens**:
  - Access token: short-lived (default 15m, controlled by `ACCESS_TOKEN_EXPIRES`), set as an **HttpOnly** cookie named `token`.
  - Refresh token: long-lived (default 7 days, controlled by `REFRESH_TOKEN_DAYS`), generated server-side and stored hashed in the DB in the `RefreshToken` model; the raw token is set as an **HttpOnly** cookie named `refreshToken` and rotated on use.
- On protected API calls, clients automatically send the `token` cookie (use `fetch(..., { credentials: 'same-origin' })`). If a request receives 401, client code attempts `POST /api/auth/refresh` to rotate refresh and obtain a new access token (handled automatically by `src/lib/fetcher.ts`).
- Security choices:
  - **HttpOnly** cookies + **SameSite=Strict** reduce XSS and CSRF risks.
  - Refresh tokens are stored hashed (not plain) and rotated/deleted on use to reduce replay risk.
- Never store JWT secrets in repo; use environment variables and a secrets manager for production.

Migration note: After pulling these changes you must run `npx prisma migrate dev` to add the `RefreshToken` table to your database.

If you‚Äôd like, I can also add a small integration test suite or a Postman collection for these auth endpoints.

---

## Cloud Secret Management (AWS Secrets Manager) üîê

**Overview:** For production, store sensitive environment variables (e.g., `DATABASE_URL`, `JWT_SECRET`) in **AWS Secrets Manager** rather than keeping them in `.env` files. Secrets Manager encrypts secrets at rest and supports IAM-based, least-privilege access and automatic rotation.

**Create a secret:**
- Console: Secrets Manager ‚Üí Store a new secret ‚Üí Other type of secret ‚Üí add JSON key/value pairs (e.g., `{"DATABASE_URL":"postgresql://...","JWT_SECRET":"..."}`)
- Name it (example): `nextjs/app-secrets` and note the **ARN**.

**Grant least-privilege access:**
- Create an IAM Role for ECS tasks with `secretsmanager:GetSecretValue` on the secret ARN.

**Retrieval (server-side):**
- This repo includes `src/lib/secrets.ts` which will fetch the secret when `SECRET_ARN` and `AWS_REGION` env vars are set. Locally it falls back to `process.env` for `DATABASE_URL` / `JWT_SECRET`.
- Install the AWS Secrets Manager client:

```bash
npm install @aws-sdk/client-secrets-manager
```

**Validate:**
- Use the API route `GET /api/secrets` to confirm keys are visible (the route returns secret keys only, not values).

```bash
# Locally (uses process.env when SECRET_ARN not set):
curl -s http://localhost:3000/api/secrets | jq

# In prod with SECRET_ARN set in task / environment, call the same endpoint and ensure keys appear
curl -s https://<your-app-url>/api/secrets | jq
```

**Rotation & policy:**
- Use Secrets Manager rotation with a Lambda for DB credentials or rotate keys monthly/quarterly depending on sensitivity.
- Document rotation ownership and timeline in this README.

---

## Container Deployment (AWS ECS - Fargate) üöÄ

**Docker:** A multi-stage `Dockerfile` is included to produce a small production image (see `Dockerfile`). `.dockerignore` excludes `.env` and build artifacts.

**ECR:** Create an ECR repository (e.g., `nextjs-app`) and push the image. The provided GitHub Actions workflow (`.github/workflows/deploy-ecs.yml`) builds the image, pushes to ECR and updates your ECS service.

**ECS Task & Service (recommended starter settings):**
- CPU: 256 (0.25 vCPU)
- Memory: 512 MB
- Port: 3000
- Health check: HTTP GET / (use ALB health checks or container health checks)
- Auto-scaling: scale 1 ‚Üí 3 tasks by CPU or request-based metrics

**Injecting secrets into task definition (ECS / Fargate):**
You can map Secrets Manager keys directly into container env vars in the task definition's `secrets` field.

Example (snippet of container definition):

```json
"secrets": [
  {
    "name": "DATABASE_URL",
    "valueFrom": "arn:aws:secretsmanager:region:account-id:secret:nextjs/app-secrets:jsonkey:DATABASE_URL::"
  },
  {
    "name": "JWT_SECRET",
    "valueFrom": "arn:aws:secretsmanager:region:account-id:secret:nextjs/app-secrets:jsonkey:JWT_SECRET::"
  }
]
```

**GitHub Actions / CI:**
- Add these Secrets to your GitHub repo: `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION`, `ECR_REPO`, `ECS_CLUSTER`, `ECS_SERVICE`.
- This repository now includes a comprehensive CI workflow at `.github/workflows/ci.yml` which runs **Lint ‚Üí Test ‚Üí Build ‚Üí Deploy (placeholder)** on push and pull requests for `main` and `develop` branches.

**CI workflow highlights**
- Lint: runs `npm run lint` (ESLint) to check code style and quality
- Test: runs `npm test -- --coverage` (Jest + RTL). Coverage thresholds are enforced in `jest.config.js` (80% global)
- Build: runs `npm run build` to ensure the Next.js app compiles
- Deploy: placeholder step runs only on `main` (replace with actual deploy commands or integrate with `deploy-ecs.yml` provided in this repo)

**Docker Build & Push (ECR)**

This repo includes a dedicated workflow to build a Docker image and push it to Amazon ECR:

- Workflow path: `.github/workflows/docker-build-push.yml`
- What it does:
  - Checks out code and configures AWS credentials from GitHub Secrets
  - Logs into ECR and builds the Docker image with `docker/build-push-action`
  - Tags the image with the git SHA and `latest`, then pushes both tags to your ECR repo
- Required GitHub Secrets:
  - `AWS_ACCESS_KEY_ID`
  - `AWS_SECRET_ACCESS_KEY`
  - `AWS_REGION`
  - `ECR_REPO` (e.g., `123456789012.dkr.ecr.us-east-1.amazonaws.com/your-repo`)

**How it triggers**
- Runs on push to `main` and can be triggered manually via the `workflow_dispatch` event.
- The pushed image tags are `${ECR_REPO}:${GITHUB_SHA}` and `${ECR_REPO}:latest`.

**Integration with ECS deployment**
- The repo already contains `.github/workflows/deploy-ecs.yml` which registers task definitions and updates the ECS service. You can either run that workflow directly or have this workflow trigger it once the image is pushed (for example via a repository_dispatch or by updating task definitions).

**Optimization & Safety**
- Caching: the build workflow uses inline cache and the registry as a cache source to speed rebuilds
- Concurrency: the workflow cancels in-progress runs on the same ref to avoid overlapping deploys
- Secrets: Do NOT hardcode secrets in workflows. Use GitHub Secrets and reference them as `${{ secrets.YOUR_SECRET }}`.

**Validation & Monitoring**
- After a push, open GitHub ‚Üí Actions ‚Üí Docker Build & Push to inspect the build and push logs.
- Confirm your image appears in ECR (AWS Console ‚Üí ECR ‚Üí Repositories ‚Üí <your-repo> ‚Üí Images).

**Next steps / Recommendations**
- Optionally trigger `deploy-ecs.yml` after a successful image push to automate full deploys (use repository dispatch or call the ECS deploy job from this workflow).
- Add an image digest or tag metadata into your release notes or CI artifacts for traceability.

**Example quick test (local)**
```bash
# Build locally
docker build -t <ECR_REPO>:local-test .
# Push (after authenticating with AWS/ECR)
# docker push <ECR_REPO>:local-test
```

**Reflections**
- Automating Docker builds in CI reduces manual steps and keeps production images reproducible.
- Using the registry and inline caching improves incremental rebuild speeds and reduces CI time.


**Validation:**
- After a push, go to GitHub ‚Üí Actions ‚Üí CI Pipeline and inspect the run. A successful run shows green checks for each step and a coverage report in the logs.

**Reflections / Tips:**
- Consider splitting long-running stages (e.g., e2e tests) into separate jobs or workflows and using artifacts to pass build outputs between jobs.
- Once CI is stable, add a coverage badge to the README and require the workflow to pass for protected branches.

**Next steps (Optional):**
- Replace the Deploy placeholder with actual deployment steps (AWS CLI / ECS deploy or Azure Web App), or trigger `deploy-ecs.yml` from this workflow via a repository dispatch.
- Add parallel jobs for lint and tests to reduce CI runtime.

---

## GitHub Actions CI/CD Pipeline üöÄ (Week 3)

This project includes a comprehensive **GitHub Actions CI/CD pipeline** that automates code quality checks, testing, building, and deployment. Every push or pull request triggers an automated workflow to validate that code meets standards before merging.

### Quick Links
- **Detailed CI/CD Guide**: See [CI_CD_PIPELINE.md](CI_CD_PIPELINE.md) for comprehensive documentation
- **Workflow File**: [.github/workflows/ci.yml](.github/workflows/ci.yml)
- **Test Reports**: After push/PR, view results in **GitHub ‚Üí Actions ‚Üí CI Pipeline**

### Pipeline Overview

The CI/CD pipeline executes **4 main stages** in sequence, with quality gates at each step:

```
Push/PR ‚Üí Lint ‚úÖ ‚Üí (Test + Build + Integration Tests in parallel) ‚Üí Deploy (main only) ‚úÖ
```

#### Stage 1: LINT üîç
- **Purpose**: Validate code style and syntax
- **Checks**:
  - ESLint: code style consistency
  - TypeScript: type safety verification
- **Failure**: Blocks entire pipeline if lint fails
- **Duration**: ~30-45 seconds

**Run locally**:
```bash
npm run lint           # Run ESLint
npm run type-check    # Run TypeScript check
```

#### Stage 2: TEST ‚úÖ
- **Purpose**: Run unit tests and verify coverage
- **Coverage Requirements**: 80%+ global coverage (lines, branches, functions, statements)
- **Tests Included**:
  - Unit tests (80+ tests for utilities, logger, monitoring)
  - API integration tests (email, contact, users endpoints)
- **Artifacts**: Coverage reports uploaded to Codecov
- **Duration**: ~20-30 seconds

**Run locally**:
```bash
npm test                          # Run all tests
npm test -- --coverage           # Run with coverage report
npm test -- __tests__/api        # Run only API tests
```

#### Stage 3: BUILD üèóÔ∏è
- **Purpose**: Verify Next.js production build succeeds
- **Checks**:
  - TypeScript compilation
  - All imports resolve correctly
  - No syntax errors
  - API routes validate
  - Next.js optimization passes
- **Artifacts**: Built `.next/` directory stored for 30 days
- **Duration**: ~45-60 seconds

**Run locally**:
```bash
npm run build    # Build for production
```

#### Stage 4: DEPLOY üöÄ (main branch only)
- **Purpose**: Deploy to production after all checks pass
- **When**: Only on push to `main` branch (not on PRs)
- **Prerequisites**: All previous stages must pass
- **Steps**:
  1. Verify build was successful
  2. Run deployment steps (placeholder, configure for AWS/Azure)
  3. Health checks
  4. Generate deployment summary
- **Duration**: ~30-45 seconds

### Workflow Triggers

The pipeline automatically triggers in these scenarios:

```yaml
on:
  push:
    branches: [main, develop]      # On commits to main/develop
  pull_request:
    branches: [main, develop]      # On PR creation/updates
  workflow_dispatch:               # Manual trigger via GitHub UI
```

#### Scenario Examples

**1. Feature Development** (on feature branch)
```bash
git push origin feature/new-api
# ‚Üí GitHub detects PR against main/develop
# ‚Üí Pipeline runs automatically
# ‚Üí Results shown in PR checks
# ‚Üí Must pass before merge
```

**2. Code Merge** (push to main)
```bash
git merge feature/new-api          # Creates local merge
git push origin main               # Push to main
# ‚Üí Pipeline runs Lint ‚Üí Test ‚Üí Build ‚Üí Deploy
# ‚Üí Deploy stage activates (only on main)
# ‚Üí Auto-deployment to production
```

**3. Manual Trigger**
- Go to **GitHub ‚Üí Actions ‚Üí CI Pipeline**
- Click **Run workflow**
- Select branch and click **Run**

### Adding GitHub Secrets

The pipeline can use secrets for credentials (AWS, Azure, Slack, etc.):

**Add a Secret**:
1. Go to **Repository Settings ‚Üí Secrets and Variables ‚Üí Actions**
2. Click **New repository secret**
3. Enter:
   ```
   Name: AWS_ACCESS_KEY_ID
   Value: AKIAIOSFODNN7EXAMPLE
   ```
4. Click **Add secret**

**Required Secrets** (if deploying to AWS):
| Secret | Usage | Example |
|--------|-------|---------|
| `AWS_REGION` | AWS region | `us-east-1` |
| `AWS_ACCESS_KEY_ID` | AWS authentication | `AKIA...` |
| `AWS_SECRET_ACCESS_KEY` | AWS authentication | `wJalr...` |
| `AWS_BUCKET_NAME` | S3 bucket | `my-app-bucket` |
| `SLACK_WEBHOOK` | Slack notifications | `https://hooks.slack.com/...` |

### Monitoring Pipeline Runs

**View Pipeline Results**:
1. Go to **GitHub ‚Üí Actions** tab
2. Select **CI Pipeline**
3. Click a workflow run
4. View logs for each job

**Understanding Status**:
- ‚úÖ **Green checkmark**: Job passed
- ‚ùå **Red X**: Job failed
- üü° **Yellow circle**: Job in progress
- ‚äò **Dash**: Job skipped (condition not met)

**View Step Details**:
- Click on a job name
- Expand any step to see logs
- Search logs for errors

**Example**: Debug a test failure
```
Actions ‚Üí CI Pipeline ‚Üí [Run ID] ‚Üí test ‚Üí npm test
‚Üí See which test failed
‚Üí Fix locally: npm test -- failing.test.ts
‚Üí Commit and push again
```

### Caching Strategy

The pipeline uses **npm caching** to speed up installs:

```yaml
- uses: actions/setup-node@v4
  with:
    cache: 'npm'    # Caches node_modules
```

**Benefits**:
- ‚ö° **50-70% faster** npm installs
- üíæ **Reduces bandwidth** usage
- üîí **Ensures consistency** across runs

**Cache hits**: Automatic when `package-lock.json` hasn't changed

### Adding a Coverage Badge

Display coverage status in your README:

```markdown
![CI Pipeline](https://github.com/YOUR-ORG/YOUR-REPO/actions/workflows/ci.yml/badge.svg)
```

Result: Shows a green "passing" or red "failing" badge

### Configuring Branch Protection

Enforce CI passing before merge:

1. Go to **Settings ‚Üí Branches**
2. Click **Add rule** under Branch protection rules
3. Select `main` as branch pattern
4. Check:
   - ‚úÖ "Require status checks to pass before merging"
   - ‚úÖ "Require branches to be up to date before merging"
5. Select status checks:
   - ‚úÖ lint
   - ‚úÖ test
   - ‚úÖ build
6. Click **Create** / **Update**

**Effect**: PRs cannot merge until pipeline passes

### Performance Statistics

**Current Pipeline Performance**:

| Stage | Duration | Node Cache | Dependencies |
|-------|----------|-----------|--------------|
| Lint | ~30-45s | ‚Äî | Already installed |
| Test | ~20-30s | ‚úÖ Cache hit | Test runs only |
| Build | ~45-60s | ‚úÖ Cache hit | Next.js compile |
| Deploy | ~30-45s | ‚Äî | Custom steps |
| **Total** | **~2-3 minutes** | ‚úÖ Optimized | Parallel jobs |

**Optimization Tips**:
- ‚úÖ Caching reduces install time significantly
- ‚úÖ Parallel jobs (test, build run together) save ~30-45s
- ‚úÖ Integration tests run in separate optional job
- ‚úÖ Deploy only on main branch (saves time on feature branches)

### Common Workflow Patterns

**Pattern 1: Feature Development**
```bash
# Local
git checkout -b feature/user-auth
# ... code changes ...
npm run lint && npm test && npm run build   # Test locally first!

# Push
git push origin feature/user-auth

# GitHub
# ‚Üí Create PR
# ‚Üí Pipeline runs automatically
# ‚Üí View results in PR checks
# ‚Üí Address any failures
# ‚Üí Merge when all checks pass
```

**Pattern 2: Hotfix to Production**
```bash
# Local
git checkout main
git pull origin main
git checkout -b hotfix/critical-bug
# ... urgent fix ...
npm run lint && npm test

# Push & merge
git push origin hotfix/critical-bug
# ‚Üí Create PR with "HOTFIX:" prefix
# ‚Üí Get fast review
# ‚Üí Merge to main
# ‚Üí Deploy stage automatically runs
# ‚Üí Fix live in production
```

**Pattern 3: Bulk Dependency Updates**
```bash
# Local
npm update
npm audit fix
npm run lint && npm test   # Verify no breaking changes!

# Push
git push origin deps/security-update
# ‚Üí Pipeline validates all updates
# ‚Üí Coverage must stay >= 80%
# ‚Üí Build must succeed
# ‚Üí Only then can merge
```

### Troubleshooting Pipeline Issues

**Problem: ESLint Fails**
```
ERROR: code ESLINTFAILURE
```

**Solution**:
```bash
# Fix locally
npm run lint -- --fix
git add .
git commit -m "style: fix linting issues"
git push
```

---

**Problem: Coverage Below Threshold**
```
ERROR: Coverage threshold not met: 80%
```

**Solution**:
```bash
# Check coverage locally
npm test -- --coverage

# Write more tests to reach 80%
# Update or create test files

# Verify locally before pushing
npm test -- --coverage
```

---

**Problem: Build Fails with "Command not found"**
```
ERROR: npm ERR! code ENOENT: command not found
```

**Solution**:
```bash
# Verify npm scripts in package.json
npm run build    # Test locally first!

# Check for missing dependencies
npm install

# Rebuild and test
npm run build
```

---

**Problem: Deployment Doesn't Trigger**
```
Deploy step skipped: condition not met
```

**Check**:
- ‚úÖ Pushed to `main` branch (not `develop`)
- ‚úÖ Used `git push` (not merged PR)
- ‚úÖ All previous stages passed (check workflow logs)

---

**Problem: Secrets Not Found**
```
ERROR: ${{ secrets.AWS_REGION }} is not defined
```

**Solution**:
1. Go to **Settings ‚Üí Secrets and Variables ‚Üí Actions**
2. Verify secret name matches exactly
3. Use default if optional:
   ```yaml
   AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
   ```

---

### Next Steps

‚úÖ **Immediate**:
1. Review [CI_CD_PIPELINE.md](CI_CD_PIPELINE.md) for detailed documentation
2. Monitor pipeline runs: **GitHub ‚Üí Actions ‚Üí CI Pipeline**
3. Add repository secrets if deploying to AWS/Azure

‚úÖ **Short Term**:
1. Configure branch protection rules (require status checks)
2. Add coverage badge to README
3. Test with a feature branch PR

‚úÖ **Long Term**:
1. Integrate deployment steps (AWS ECS, Azure, Vercel)
2. Add Slack notifications for failures
3. Implement E2E test stage
4. Monitor performance metrics

---

## Domain & SSL (Route 53 + ACM) üîí

**Overview:** Configure a custom domain via **Route 53** and secure traffic with an **AWS Certificate Manager (ACM)** public certificate. Attach the certificate to your Load Balancer (ALB) or CloudFront distribution so users access your app over HTTPS.

**Register or connect a domain:**
- If you own a domain, change its nameservers to the ones provided by Route 53 (Hosted Zone ‚Üí NS records). If not, register via Route 53 or your registrar.

**Create a Hosted Zone:**
1. Route 53 ‚Üí Hosted Zones ‚Üí Create Hosted Zone ‚Üí enter `example.com`.
2. Copy NS records and update your registrar to point to Route 53 nameservers.

**Request a public certificate (ACM) with DNS validation:**
- ACM ‚Üí Request certificate ‚Üí Public certificate ‚Üí add `example.com` and `*.example.com` ‚Üí DNS validation.
- ACM will provide a CNAME validation record; create it in Route 53 (Record type: CNAME) and wait for the status to change to **Issued**.

**Attach certificate to your ALB / CloudFront:**
- ALB: Create / Edit listener on port 443, select the ACM certificate, and ensure you have an HTTP ‚Üí HTTPS redirect rule on port 80 that redirects to 443 (HTTP 301 or 302).
- CloudFront: Configure the distribution to use the ACM certificate (in us-east-1 for CloudFront) and point origin to your ALB or ECS service endpoint.

**Route 53 records (example):**
- Root A record (Alias) ‚Üí points to ALB DNS name (choose Alias yes)
- `www` CNAME ‚Üí `example.com`

**Force HTTPS & HSTS:**
- At the ALB level: Add a listener rule to redirect HTTP (80) ‚Üí HTTPS (443).
- Application-level: Set `ENFORCE_HTTPS=true` and consider enabling `ENABLE_HSTS=true` in your task env to add HSTS headers (the middleware already sets Strict-Transport-Security when `ENABLE_HSTS` is true or in production).

**Validation checklist:**
- [ ] DNS A/ALIAS records point to load balancer and have propagated (use `dig`/`nslookup`).
- [ ] ACM certificate status is **Issued**.
- [ ] ALB listener on 443 uses the ACM certificate and health checks pass.
- [ ] Visiting https://example.com shows the padlock üîí and the browser Security tab shows a valid certificate.
- [ ] Run SSL checks: https://www.ssllabs.com/ssltest/ (score A+ recommended)

**Automation & renewal:**
- ACM public certificates are provisioned and renewed automatically when validated via DNS (no manual renewal step required).

**Notes & troubleshooting:**
- If using CloudFront, request the certificate in `us-east-1` and use DNS validation there.
- If the certificate stays in **Pending validation**, ensure the CNAME validation record exists in the correct Route 53 hosted zone and that TTLs have expired.
- For staging vs production, use subdomains (e.g., `staging.example.com`) and separate certificates or wildcard certificates.

**Screenshot checklist to add to README:**
- Route 53 Hosted Zone record set (show NS / A records)
- ACM certificate status (`Issued`)
- Browser showing HTTPS padlock for `https://example.com`


## Logging & Monitoring (AWS CloudWatch) üìà

**Goals:** Emit structured JSON logs with correlation IDs, collect container logs in CloudWatch Logs, create metric filters for error rates, and configure dashboards and alerts for operational visibility.

### Structured logs (JSON)
- Use a consistent schema: `timestamp`, `level`, `message`, `requestId` (correlation id), and additional metadata (userId, path, statusCode).
- This repo includes `src/lib/logger.ts` which prints JSON logs ready for CloudWatch ingestion. Example log:

```json
{"timestamp":"2025-12-30T10:00:00.000Z","level":"error","message":"Failed to process request","requestId":"1670000000000","userId":123}
```

### ECS task definition: send logs to CloudWatch Logs
Add a `logConfiguration` to the container definition in your task definition so that each container sends stdout/stderr to CloudWatch:

```json
"logConfiguration": {
  "logDriver": "awslogs",
  "options": {
    "awslogs-group": "/ecs/nextjs-app",
    "awslogs-region": "ap-south-1",
    "awslogs-stream-prefix": "ecs"
  }
}
```

Create the log group (or let ECS create it automatically):

```bash
aws logs create-log-group --log-group-name /ecs/nextjs-app --region ap-south-1
aws logs put-retention-policy --log-group-name /ecs/nextjs-app --retention-in-days 14 --region ap-south-1
```

### Metric filter & alarm (example: count error logs)
Create a metric filter to count logs where `level` is `error`:

```bash
aws logs put-metric-filter \
  --log-group-name "/ecs/nextjs-app" \
  --filter-name "ErrorCount" \
  --filter-pattern '{ $.level = "error" }' \
  --metric-transformations metricName=ErrorCount,metricNamespace=NextJSApp,metricValue=1

# Create an alarm on that metric (example: >10 errors in 5 minutes)
aws cloudwatch put-metric-alarm \
  --alarm-name "NextJS-High-Errors" \
  --metric-name ErrorCount \
  --namespace NextJSApp \
  --statistic Sum \
  --period 300 \
  --threshold 10 \
  --comparison-operator GreaterThanThreshold \
  --evaluation-periods 1 \
  --alarm-actions <SNS_TOPIC_ARN>
```

### Logs Insights query example (trace errors by hour)

```
fields @timestamp, @message
| parse @message /"level":\s*"(?<level>[^\"]+)"/
| filter level = "error"
| stats count() by bin(1h)
```

### Dashboards & alerts
- Build a CloudWatch Dashboard showing: ErrorCount (metric), Average response latency, Container CPU/Memory usage.
- Configure alerts to notify via SNS (email/Slack webhook) when thresholds are crossed.

### Retention & archival
- Keep operational logs for 7‚Äì14 days and audit logs longer (90+ days) depending on compliance needs.
- Archive logs to S3 for long-term storage using a Lambda or Lifecycle export if needed.

### Validation checklist
- [ ] CloudWatch Log Group `/ecs/nextjs-app` exists and receives logs.
- [ ] Metric filter `ErrorCount` is created and shows non-zero data when errors occur.
- [ ] Dashboard shows relevant metrics and alarms are configured to notify the on-call channel.


### Notes
- Use structured logs ‚Äî they make metric extraction and searching far more reliable.
- Correlate application logs with X-Ray traces or request metrics for full-stack observability.


### Example: Refresh flow (curl)
1) Login (sets cookies):

```bash
curl -i -X POST http://localhost:3000/api/auth/login -H "Content-Type: application/json" -d '{"email":"demo-user@example.com","password":"demo"}'
```

2) Trigger protected API (using cookie set by login):

```bash
curl -i -X GET http://localhost:3000/api/users -b "cookie.txt"
```

3) If access token expired (401), call refresh to obtain new access token (cookies are rotated automatically):

```bash
curl -i -X POST http://localhost:3000/api/auth/refresh -b "cookie.txt" -c "cookie.txt"
```

4) Logout (clears cookies and revokes refresh tokens):

```bash
curl -i -X POST http://localhost:3000/api/auth/logout -b "cookie.txt"
```


---

## Authorization Middleware & RBAC (Role-Based Access Control) üîê

This project includes a reusable middleware (`app/middleware.ts`) that validates JWTs and enforces role-based access for API routes.

### Behavior
- The middleware runs for `/api/users/*` and `/api/admin/*` (configured via `matcher`).
- It expects `Authorization: Bearer <token>` header and verifies the token using `JWT_SECRET`.
- On success the middleware adds `x-user-email` and `x-user-role` headers for downstream handlers.
- Access rules:
  - `/api/users` ‚Äî any authenticated user can access (general protected route)
  - `/api/admin` ‚Äî restricted to users with `role === "admin"` (admin-only)

### Example: Protected Admin Route
- Request (admin):
  - curl -X GET http://localhost:3000/api/admin \
    -H "Authorization: Bearer <ADMIN_JWT>"
- Successful response (200):
  - { "success": true, "message": "Welcome Admin! You have full access." }

- Request (regular user):
  - curl -X GET http://localhost:3000/api/admin \
    -H "Authorization: Bearer <USER_JWT>"
- Response (403):
  - { "success": false, "message": "Access denied" }

### Example: General Protected Route `/api/users`
- Request without token:
  - curl -X GET http://localhost:3000/api/users
- Response (401):
  - { "success": false, "message": "Token missing" }

- Request with valid token:
  - curl -X GET http://localhost:3000/api/users \
    -H "Authorization: Bearer <USER_JWT>"
- Response (200): contains paginated users and a `meta` object that shows who accessed and the role.

### Notes & Reflection
- Principle of least privilege: only routes that need elevated permissions are restricted to the `admin` role; ordinary routes require authentication only.
- Extensibility: Add new roles (e.g., `editor`, `moderator`) in the database and extend middleware checks (or use a role->permission map) to manage fine-grained permissions.
- Testing: Use the `/api/auth/login` route to obtain tokens for users with different roles and exercise the protected endpoints.

---

## Centralized Error Handling & Structured Logging üõ†Ô∏è

This project includes a small, reusable error handling utility (`src/lib/errorHandler.ts`) and a structured logger (`src/lib/logger.ts`) to centralize error classification, logging and safe user responses.

### logger (src/lib/logger.ts)
- Lightweight structured logger that outputs JSON lines for `info` and `error`.
- Example usage:

```ts
import { logger } from "@/lib/logger";
logger.error("DB failed", { message: err.message, stack: err.stack });
```

### handleError (src/lib/errorHandler.ts)
- Call `handleError(error, context)` from route catch blocks for consistent logging and user-friendly messages.
- Behavior:
  - In **development** (`NODE_ENV !== 'production'`): response includes `message` and `stack`.
  - In **production**: response message is redacted to `"Something went wrong. Please try again later."` and the stack is logged as `"REDACTED"`.

### Example usage in a route
```ts
import { handleError } from "@/lib/errorHandler";

export async function GET() {
  try {
    throw new Error("Database connection failed!");
  } catch (error) {
    return handleError(error, "GET /api/users");
  }
}
```

### Example logs
- Development console (detailed):
```json
{"level":"error","message":"Error in GET /api/users","meta":{"message":"Database connection failed!","stack":"Error: Database connection failed! at ..."},"timestamp":"2025-10-29T16:45:00Z"}
```
- Production console (redacted):
```json
{"level":"error","message":"Error in GET /api/users","meta":{"message":"Database connection failed!","stack":"REDACTED"},"timestamp":"2025-10-29T16:45:00Z"}
```

### Why this helps
- **Consistency**: All unhandled errors follow a single format and route for logging.
- **Security**: Stack traces are redacted in production responses to avoid leaking internals.
- **Observability**: JSON logs are easy to ship to CloudWatch, Datadog, ELK, etc.

---

If you want, I can also add a comparison table for dev vs prod output, or wire the logger to `pino`/`winston` for more advanced features. Let me know which you'd prefer.

---

## Redis Caching (Cache-Aside Pattern) ‚ö°

This project includes a simple Redis integration to cache frequently-read API responses and reduce database load.

### Setup
- Install the client:
  - `npm install ioredis`
- Environment variable:
  - `REDIS_URL` ‚Äî e.g. `redis://localhost:6379`
  - Optional TTL:
    - `REDIS_TTL` (seconds, default `60`)
- Client utility: `src/lib/redis.ts` exports a connected redis client.

### Strategy
- We use **cache-aside** (lazy loading): check cache first; on miss, query DB and populate Redis with a TTL.
- Cache keys for users list use parameters: `users:list:<page>:<limit>:<q>` to support pagination & search.

### Example: `GET /api/users` (simplified)
```ts
const cacheKey = `users:list:${page}:${limit}:${q || ""}`;
const cached = await redis.get(cacheKey);
if (cached) return sendSuccess(JSON.parse(cached));
// otherwise fetch from DB
await redis.set(cacheKey, JSON.stringify(payload), "EX", ttl);
```

### Invalidation
- On user create/update/delete, delete keys matching `users:list*` to avoid stale results:
```ts
const keys = await redis.keys("users:list*");
if (keys.length) await redis.del(...keys);
```

### Example logs & behavior
- Cold request (cache miss):
  - `Cache Miss - Fetching from DB` ‚Üí DB query ‚Üí cache the result (TTL 60s)
- Subsequent request (cache hit):
  - `Cache Hit` ‚Üí returned from Redis (much faster)

### Notes & Reflection
- TTL balances freshness vs performance; set shorter TTL for rapidly-changing data.
- Invalidation must be performed on writes to keep cache coherent. For large-scale systems, consider more robust patterns (pub/sub invalidation, cache versioning, or fine-grained keys).
- For production use, consider a managed Redis service and enable monitoring (latency, hit/miss rate).

---

## Security Headers ‚Äî HTTPS, HSTS, CSP & CORS üîê

This project enforces important security headers and provides middleware to help you enforce HTTPS, HSTS, Content Security Policy (CSP), and CORS for API routes.

### What was added
- **Global headers** (via `next.config.ts`): `Content-Security-Policy`, `X-Frame-Options`, `X-Content-Type-Options`, `Referrer-Policy`, `Permissions-Policy` and **Strict-Transport-Security** (HSTS) when running in production or when `ENABLE_HSTS=true`.
- **Middleware (`app/middleware.ts`)**:
  - Optional HTTPS enforcement/redirect when `NODE_ENV=production` or `ENFORCE_HTTPS=true`.
  - Adds HSTS and other security headers to all responses (in production).
  - Handles CORS for `/api/*` routes, including `OPTIONS` preflight handling and dynamic `Access-Control-Allow-Origin` based on `CORS_ORIGINS` environment variable.

### Configuration (env)
- `ENFORCE_HTTPS` ‚Äî set to `true` to redirect HTTP ‚Üí HTTPS in non-production testing environments.
- `ENABLE_HSTS` ‚Äî set to `true` to add HSTS header even during testing.
- `CSP_DIRECTIVES` ‚Äî overrides the CSP header (default: `default-src 'self'; script-src 'self'; img-src 'self' data:; style-src 'self' 'unsafe-inline';`).
- `CORS_ORIGINS` ‚Äî comma-separated list of allowed origins for API access (default: `http://localhost:3000`).

### How to test locally
- Start dev server: `npm run dev`.
- Example curl to inspect headers on a page:
  - curl -I http://localhost:3000/
- Example curl to test CORS preflight (replace origin):
  - curl -i -X OPTIONS http://localhost:3000/api/users -H "Origin: http://localhost:3000" -H "Access-Control-Request-Method: POST"
- In the browser: open DevTools ‚Üí Network ‚Üí click a request ‚Üí check the **Response headers** for `Content-Security-Policy`, `Strict-Transport-Security`, `Access-Control-Allow-Origin`, etc.

### Security scan recommendations
- Use https://securityheaders.com/ or https://observatory.mozilla.org/ to scan your deployed domain.
- Test changes in staging before making CSP stricter in production ‚Äî strict CSPs can break third-party integrations (analytics, fonts).

### Notes & Future improvements
- If deploying behind a proxy or CDN (e.g., Vercel, CloudFront), ensure the `x-forwarded-proto` header is set so the middleware can detect secure requests.
- Consider adding a CSP report-uri to collect CSP violations and iteratively tighten policies.
- Consider adding automated CI checks (e.g., a simple curl-based header check) to fail builds if headers are missing.

---

## File Uploads (AWS S3 / Azure Blob) üóÇÔ∏è

This project implements pre-signed URL uploads so clients can upload files directly to cloud storage without streaming large files through the app server.

### Packages
- AWS: `@aws-sdk/client-s3` and `@aws-sdk/s3-request-presigner`
- Azure: `@azure/storage-blob`

Install:
- `npm install @aws-sdk/client-s3 @aws-sdk/s3-request-presigner @azure/storage-blob`

### Environment variables
- Storage selection (optional):
  - `STORAGE_PROVIDER` ‚Äî `aws` (default) or `azure`

- AWS (if using AWS):
  - `AWS_ACCESS_KEY_ID`
  - `AWS_SECRET_ACCESS_KEY`
  - `AWS_REGION`
  - `AWS_BUCKET_NAME`

- Azure (if using Azure):
  - `AZURE_ACCOUNT_NAME`
  - `AZURE_ACCOUNT_KEY`
  - `AZURE_CONTAINER_NAME`

- Common:
  - `UPLOAD_URL_EXPIRES` ‚Äî seconds the presigned URL is valid (default `60`)
  - `MAX_UPLOAD_SIZE` ‚Äî maximum upload size in bytes (default `10000000` = 10MB)
  - `FILE_UPLOAD_PREFIX` ‚Äî optional path prefix inside the bucket/container (default `uploads`)

### Flow
1. Client requests a pre-signed URL from `POST /api/upload` with `{ filename, fileType, size }`.
2. Server validates file type/size and returns a pre-signed `uploadURL` (method: PUT) and a `publicUrl` where the object will be available (subject to bucket/container ACLs).
3. Client uploads directly to the storage provider using the `uploadURL`.
4. After successful upload, client calls `POST /api/files` with `{ fileName, fileURL, size, mime }` to persist metadata in the DB.

### Example: request presigned URL
```bash
curl -s -X POST http://localhost:3000/api/upload \
  -H "Content-Type: application/json" \
  -d '{"filename":"profile.png","fileType":"image/png","size":43212}'
```
Response (success):
```json
{ "success": true, "upload": { "uploadURL": "https://...", "key":"uploads/...,", "publicUrl":"https://...", "method":"PUT", "expiresIn":60 } }
```

### Example: store file metadata
```bash
curl -s -X POST http://localhost:3000/api/files \
  -H "Content-Type: application/json" \
  -d '{"fileName":"profile.png","fileURL":"https://...","size":43212,"mime":"image/png" }'
```
Response:
```json
{ "success": true, "message": "File record created", "data": { /* new file record */ } }
```

### IAM / SAS snippets & best practices

AWS (minimal S3 policy for uploading/reading objects in a single bucket):

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:PutObject", "s3:GetObject"],
      "Resource": ["arn:aws:s3:::your-bucket-name/*"]
    }
  ]
}
```

Azure (SAS token permissions example):

- Generate a SAS token with `Write` and `Create` permissions scoped to a single container and a short expiry time.

Security best practices:

- **Block public access** on the bucket/container for private apps.
- Use short expirations for presigned URLs (30‚Äì120s) and narrow permissions for SAS tokens.
- Store cloud credentials in a secrets manager (AWS Secrets Manager, Azure Key Vault) and never commit them to source control.

### Security & lifecycle
- Validate file types and sizes server-side as a last line of defense.
- Use short expiry for presigned URLs (30‚Äì120s recommended).
- Apply appropriate bucket/container ACLs: use private by default and return signed access URLs to clients if necessary.
- Configure lifecycle policies to archive or delete old files to control cost.

### Local test UI & verification

- Install the necessary SDK packages locally if you plan to run AWS/Azure code: `npm install @aws-sdk/client-s3 @aws-sdk/s3-request-presigner @azure/storage-blob`.
- Start dev server: `npm run dev` and visit `/upload-demo` to test the end-to-end flow in the browser.
- After uploading, verify the file is available (if public or your bucket allows) with the helper script:
  - `npm run verify:upload https://your-bucket.s3.region.amazonaws.com/.../file.jpg`

---

## Transactional Email (AWS SES / SendGrid) ‚úâÔ∏è

This project includes a small email utility (`src/lib/email.ts`) that supports **AWS SES** and **SendGrid**. Use `EMAIL_PROVIDER` env var to choose the provider (`ses` by default).

### Packages
- AWS: `@aws-sdk/client-ses`
- SendGrid: `@sendgrid/mail`

Install:
- `npm install @aws-sdk/client-ses` or `npm install @sendgrid/mail`

### Environment variables
- Common:
  - `EMAIL_PROVIDER` ‚Äî `ses` or `sendgrid` (default `ses`)

- AWS SES:
  - `AWS_ACCESS_KEY_ID`
  - `AWS_SECRET_ACCESS_KEY`
  - `AWS_REGION`
  - `SES_EMAIL_SENDER` ‚Äî verified sender (e.g., `no-reply@yourdomain.com`)

- SendGrid:
  - `SENDGRID_API_KEY`
  - `SENDGRID_SENDER` ‚Äî verified sender email

### Usage
- Route: `POST /api/email` accepts `{ to, subject, message }` and returns provider-specific success info.

Example:
```bash
curl -s -X POST http://localhost:3000/api/email \
  -H "Content-Type: application/json" \
  -d '{"to":"student@example.com","subject":"Welcome!","message":"<h3>Hello from QConnect üöÄ</h3>"}'
```
Success response (SES):
```json
{ "success": true, "provider": "ses", "messageId": "01010189b2example123" }
```

### Template example
- `src/lib/templates/emailTemplates.ts` exposes `welcomeTemplate(userName)`.
- Use it like:
```ts
import { welcomeTemplate } from "@/lib/templates/emailTemplates";
import { sendEmail } from "@/lib/email";

await sendEmail({ to: user.email, subject: "Welcome to QConnect", html: welcomeTemplate(user.name) });
```

---

## Page routing & dynamic pages (App Router)

This project uses the Next.js App Router under `src/app` and includes public and protected pages plus dynamic user pages.

### Routes overview
- Public:
  - `/` ‚Äî home (existing `src/app/page.tsx`)
  - `/login` ‚Äî login page (client)
- Protected (middleware redirects to `/login` if unauthenticated):
  - `/dashboard` ‚Äî protected dashboard
  - `/users` ‚Äî protected users list (server-rendered)
  - `/users/[id]` ‚Äî dynamic user profile
- Custom 404: `src/app/not-found.tsx`

### Component architecture & Layout
- Components are organized under `src/components`:
  - `src/components/layout` ‚Äî `Header`, `Sidebar`, `LayoutWrapper`
  - `src/components/ui` ‚Äî reusable UI elements like `Button`
  - `src/components/index.ts` ‚Äî barrel export for easy imports

- The global layout (`src/app/layout.tsx`) now uses `LayoutWrapper` so every page gets the shared header and sidebar automatically.

### Key snippets
- Middleware handles both API and page protection. For pages it checks cookie `token` and redirects to `/login` if missing or invalid.

- Example client login (sets cookie):
```ts
// src/app/login/page.tsx (client)
// submits to /api/auth/login, sets cookie `token`, then router.push('/dashboard')
```

- Example protected server page (users list):
```ts
// src/app/users/page.tsx
const users = await prisma.user.findMany({ select: { id, name, email } });
```

### How to test
1. Start dev server: `npm run dev`
2. Visit `/login` and sign in with seeded user (e.g., `demo-user@example.com`) or create one via the signup endpoint.
3. After successful login you'll be redirected to `/dashboard` and can visit `/users` and `/users/1`.

### Reflection
- Dynamic routes (`[id]`) make it easy to scale resource pages (users, appointments).
- Middleware centralizes page protection and keeps UI code simple.
- Use server-rendered pages for SEO-sensitive content and to avoid exposing internal APIs to the client.

---

## Component Architecture & Reusable UI üß©

A small component library was added under `src/components` to encourage reusability and consistent UI across pages.

### Folder structure
- `src/components/layout` ‚Äî `Header.tsx`, `Sidebar.tsx`, `LayoutWrapper.tsx` (LayoutWrapper composes Header + Sidebar)
- `src/components/ui` ‚Äî `Button.tsx` (reusable UI element)
- `src/components/index.ts` ‚Äî barrel export for convenience

### Header
- Accessible header with role="banner" and nav label. Use `<Link>` from `next/link` for navigation.

### Sidebar
- Sidebar exposes contextual navigation and uses semantic `aside` with `role="navigation"`.

### LayoutWrapper
- Composes `Header` + `Sidebar` and provides page content area. Pages are rendered inside the layout wrapper so they inherit the shared navigation and spacing.

### Button (ui)
- Small, accessible button component with `primary` and `secondary` variants and an optional `ariaLabel` prop.

### Accessibility & Best Practices
- Use semantic elements (`header`, `nav`, `aside`, `main`) and `aria-*` attributes where appropriate.
- Keep interactive components keyboard accessible and provide visible focus styles (use CSS).

### Example usage
```tsx
import { LayoutWrapper, Button } from '@/components';

export default function Page() {
  return (
    <LayoutWrapper>
      <h1>Page</h1>
      <Button label="Create" />
    </LayoutWrapper>
  );
}
```

---

## Loading & Error States (Skeletons & Error Boundaries) ‚è≥‚ùå

To make the app resilient and communicative during async operations, the project includes route-level loading skeletons and error fallback UIs using Next.js App Router conventions.

### What I added
- `src/components/ui/Skeleton.tsx` ‚Äî small skeleton helper component using `animate-pulse`.
- Route-level fallbacks:
  - `src/app/loading.tsx` ‚Äî global loading skeleton for top-level navigation.
  - `src/app/error.tsx` ‚Äî global error boundary with retry button.
  - `src/app/users/loading.tsx` & `src/app/users/error.tsx` ‚Äî route-specific skeleton & retry-friendly error UI.
  - `src/app/users/[id]/loading.tsx` & `src/app/users/[id]/error.tsx` ‚Äî per-user loading & error fallbacks.

### How to simulate states
- Slow fetch: set `SLOW_FETCH_MS` env var (number of milliseconds) to simulate network delay for server pages. Example:

  - In development run: `SLOW_FETCH_MS=2000 npm run dev`
  - Or set it in your `.env` file for a persistent delay.

- Error testing: you can throw an error inside a page for testing (e.g., `if (!data) throw new Error('Failed')`) or use browser/Network tab to throttle and disconnect.

### UX decisions
- Skeletons give users a sense of content structure rather than an ambiguous spinner.
- Error fallbacks include a prominent retry button (`reset()`), which re-renders the route and attempts to fetch again.

---

## Responsive & Themed Design (Tailwind) üé®üì±


## Feedback UI: Toasts, Modals & Loaders üîîüõë‚è≥

This project includes a small set of accessible feedback components to improve user confidence and UX:

- **Toasts (instant feedback)** ‚Äî implemented with `sonner`. A global `<Toaster />` is mounted in `src/app/layout.tsx` so you can call `toastSuccess()`, `toastError()` or `toastLoading()` from anywhere via `src/lib/toast.ts`.
- **Confirm Modal (blocking confirmation)** ‚Äî a promise-based confirmation dialog implemented via `src/context/ModalContext.tsx` and rendered by `src/components/ui/ConfirmModal.tsx`. Use `const { confirm } = useModal()` and `await confirm({ title, description })` to prompt the user.
- **Spinner / Loader (process feedback)** ‚Äî `src/components/ui/Spinner.tsx` provides a small SVG spinner used in buttons and list items while asynchronous operations run.

Accessibility and behavior:
- Toasts are announced politely via the underlying library and disappear automatically.
- The confirm modal uses `role="dialog"`, `aria-modal="true"`, focus trapping (Tab) and closes on `Escape`.
- Loaders include `role="status"` where appropriate and are non-blocking unless placed inside a blocking modal.

Where used in the demo:
- `src/components/users/AddUser.tsx` ‚Äî shows a spinner in the button during creation and shows success/error toasts.
- `src/components/users/UsersSWRList.tsx` ‚Äî delete actions prompt the confirm modal, show a spinner while deleting and display success/error toasts.
- `src/app/contact/page.tsx` & `src/app/signup/page.tsx` ‚Äî submission flows use loading spinners and toasts to indicate progress and result.

How to enable locally:
1. Install the toast dependency: `npm install` (we added `sonner` to `package.json`, run `npm install` locally if you haven't yet).
2. Start dev server: `npm run dev` and visit the pages mentioned above.

Design notes:
- Keep toasts succinct (2‚Äì4 words for success), and avoid stacking too many toasts.
- Modals should be used for destructive or irreversible actions only (deletion, approvals).
- Use loaders for any operation that takes a noticeable time (file uploads, long API calls). This improves perceived performance.

---

## Context & Hooks (Auth + UI State) üß≠

This project adds a small, demo-ready global state solution using React Context and custom hooks:

Structure:
- `src/context/AuthContext.tsx` ‚Äî `AuthProvider` + `useAuthContext()` (stores a `user` object and exposes `login`/logout).
- `src/context/UIContext.tsx` ‚Äî `UIProvider` + `useUIContext()` (stores `theme` and `sidebarOpen`).
- `src/hooks/useAuth.ts` ‚Äî `useAuth()` custom hook that returns `{ isAuthenticated, user, login, logout }`.
- `src/hooks/useUI.ts` ‚Äî `useUI()` custom hook that returns `{ theme, toggleTheme, sidebarOpen, toggleSidebar }`.

### Usage
- Wrap your app with the providers (done in `src/app/layout.tsx`):
```tsx
<AuthProvider>
  <UIProvider>
    <LayoutWrapper>{children}</LayoutWrapper>
  </UIProvider>
</AuthProvider>
```

- Demo page: `src/app/context-demo/page.tsx` shows login/logout and theme/sidebar toggles.

### Notes & Best Practices
- The provided context is intentionally simple (demo): it stores some state in `localStorage` for hydration and logs events to console for visibility.
- For complex state or many actions, prefer `useReducer` to centralize updates and avoid unnecessary re-renders.
- Use React DevTools to inspect provider values and memoize consumers where appropriate.

---

## Client-side Data Fetching with SWR ‚ö°

This project demonstrates client-side data fetching using **SWR** (stale-while-revalidate) for caching, revalidation and optimistic updates.

### Install
- `npm install swr`

### Fetcher helper (`src/lib/fetcher.ts`)
- Provides a small wrapper that maps the API response envelope (`{ success, data }`) to the payload returned to components:
```ts
export const fetcher = async (url: string) => {
  const res = await fetch(url, { credentials: "same-origin" });
  if (!res.ok) throw new Error(`Failed to fetch: ${res.status}`);
  const body = await res.json();
  if (!body.success) throw new Error(body.message || "API error");
  return body.data; // e.g., { page, limit, total, data: [...] }
};
```

### Example: client-side users list
- `src/components/users/UsersSWRList.tsx` uses `useSWR('/api/users', fetcher)` and renders `payload.data`.
- It shows `isValidating` and handles errors.

### Example: optimistic add
- `src/components/users/AddUser.tsx` performs an optimistic update using `mutate('/api/users')`:
  - Immediately updates UI with a temporary user
  - Calls `POST /api/users`
  - Revalidates the `/api/users` key after the request to sync server state

### How to test
1. Start dev server: `npm run dev`
2. Visit `/users` - page contains server-side list and a client-side SWR demo section.
3. Use the Add User form to test optimistic UI (immediate UI update, background revalidation).
4. Observe caching behavior and revalidation in React DevTools ‚Üí SWR cache.

### Notes
- SWR keys uniquely identify cache entries ‚Äî use stable keys (strings or arrays for parameterized requests).
- Use `mutate(key, data, false)` for optimistic UI and then `mutate(key)` to revalidate.
- Use `onErrorRetry` or `refreshInterval` to tune revalidation and resilience.

---

## Email Service Integration ‚úâÔ∏è

QConnect integrates transactional email functionality using either **AWS SES** or **SendGrid**. This system sends automated notifications for critical events like user signups, password resets, appointment reminders, and security alerts.

### Why Transactional Emails Matter

Transactional emails are essential for user engagement and trust. Unlike marketing emails, they are **trigger-based** and sent automatically in response to user actions:

| Event | Email Type | Purpose |
|-------|-----------|---------|
| User signs up | Welcome email | Confirm account creation |
| Password reset request | Reset link | Enable account recovery |
| Appointment scheduled | Confirmation | Notify doctor & patient |
| Appointment reminder | Reminder | Reduce no-shows |
| Security event | Alert | Protect account |

### Choosing Your Provider

Both AWS SES and SendGrid are production-ready. Choose based on your needs:

| Feature | AWS SES | SendGrid |
|---------|---------|----------|
| **Pricing** | Pay-per-email ($0.10/1000) | Free tier (100/day), then $0.0001/email |
| **Setup** | Requires AWS account + domain verification | Create account + API key |
| **Ideal for** | Backend automation at scale | Rapid development, small volume |
| **Sandbox Mode** | Requires email verification | Full API access |
| **Bounce Handling** | SNS notifications | Event API |

### Setup & Configuration

#### Option A: AWS SES Setup

1. **Create AWS Account** and navigate to [Simple Email Service (SES)](https://console.aws.amazon.com/ses/)

2. **Verify Email/Domain**:
   - In sandbox mode: verify individual recipient emails in the AWS SES console
   - In production: verify your domain (requires DNS records for DKIM/SPF)

3. **Get AWS Credentials**:
   - Create an IAM user with `AmazonSESFullAccess` policy
   - Generate access key + secret key

4. **Add to `.env`**:
   ```bash
   EMAIL_PROVIDER=ses
   AWS_REGION=ap-south-1
   AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
   AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
   SES_EMAIL_SENDER=no-reply@yourdomain.com
   ```

5. **Install Dependencies**:
   ```bash
   npm install @aws-sdk/client-ses
   ```

#### Option B: SendGrid Setup

1. **Create SendGrid Account** at [sendgrid.com](https://sendgrid.com)

2. **Verify Sender Email**:
   - Go to Settings ‚Üí Sender Authentication
   - Verify your email address or domain

3. **Generate API Key**:
   - Settings ‚Üí API Keys
   - Create "Full Access" API key

4. **Add to `.env`**:
   ```bash
   EMAIL_PROVIDER=sendgrid
   SENDGRID_API_KEY=SG.abc123...
   SENDGRID_SENDER=no-reply@yourdomain.com
   ```

5. **Install Dependencies**:
   ```bash
   npm install @sendgrid/mail
   ```

### Email Implementation

#### Email Service Library

The email system is implemented in [src/lib/email.ts](src/lib/email.ts):

```typescript
import { sendEmail } from "@/lib/email";

// Send an email
const result = await sendEmail({
  to: "user@example.com",
  subject: "Welcome to QConnect",
  html: "<h3>Hello! üéâ</h3>",
  from: "no-reply@yourdomain.com" // optional, uses env default
});

// Result: { success: true, provider: "ses", messageId: "01010189..." }
```

#### API Route

POST `/api/email` ‚Äî Send transactional email

**Request**:
```json
{
  "to": "user@example.com",
  "subject": "Welcome!",
  "message": "<h3>Hello from QConnect üöÄ</h3>"
}
```

**Response**:
```json
{
  "success": true,
  "provider": "ses",
  "messageId": "01010189b2example123"
}
```

**Test with cURL**:
```bash
curl -X POST http://localhost:3000/api/email \
  -H "Content-Type: application/json" \
  -d '{
    "to": "student@example.com",
    "subject": "Welcome!",
    "message": "<h3>Hello from QConnect üöÄ</h3>"
  }'
```

### Email Templates

Pre-built HTML templates are in [src/lib/templates/emailTemplates.ts](src/lib/templates/emailTemplates.ts):

#### Welcome Email
```typescript
import { welcomeTemplate } from "@/lib/templates/emailTemplates";

const html = welcomeTemplate("John Doe");
await sendEmail({
  to: "john@example.com",
  subject: "Welcome to QConnect!",
  html
});
```

**Output**:
```html
<h2>Welcome to QConnect, John Doe!</h2>
<p>We're thrilled to have you onboard üéâ</p>
<p>Start managing your appointments and doctors...</p>
<a href="https://app.qconnect.local/dashboard">Get Started</a>
```

#### Password Reset Email
```typescript
import { passwordResetTemplate } from "@/lib/templates/emailTemplates";

const resetLink = "https://app.qconnect.local/reset?token=abc123";
const html = passwordResetTemplate("John Doe", resetLink, 24);
await sendEmail({
  to: "john@example.com",
  subject: "Reset Your Password",
  html
});
```

#### Appointment Reminder Email
```typescript
import { appointmentReminderTemplate } from "@/lib/templates/emailTemplates";

const html = appointmentReminderTemplate(
  "John Doe",
  "Smith",
  "Jan 20, 2026 at 2:30 PM",
  "Consultation - Room 101"
);
await sendEmail({
  to: "john@example.com",
  subject: "Appointment Reminder",
  html
});
```

#### Security Alert Email
```typescript
import { securityAlertTemplate } from "@/lib/templates/emailTemplates";

const html = securityAlertTemplate(
  "John Doe",
  "Unusual login from 192.168.1.1",
  true
);
await sendEmail({
  to: "john@example.com",
  subject: "Security Alert",
  html
});
```

#### Custom Notification Email
```typescript
import { notificationTemplate } from "@/lib/templates/emailTemplates";

const html = notificationTemplate(
  "John Doe",
  "Payment Received",
  "Your appointment payment of $50 was received.",
  "https://app.qconnect.local/invoices",
  "View Invoice"
);
await sendEmail({
  to: "john@example.com",
  subject: "Payment Confirmation",
  html
});
```

### Email Logging & Monitoring

Email sends are logged using [src/lib/emailLogger.ts](src/lib/emailLogger.ts):

```typescript
import { logEmailSent, logEmailFailed, getEmailStats } from "@/lib/emailLogger";

// Logs are automatically created in sendEmail()
// Retrieve statistics:
const stats = getEmailStats();
console.log(stats);
// {
//   totalSent: 42,
//   successful: 40,
//   failed: 2,
//   successRate: "95.24",
//   byProvider: { ses: 25, sendgrid: 15 }
// }

// Get recent email logs
import { getEmailLogs } from "@/lib/emailLogger";
const logs = getEmailLogs({ status: "success", limit: 10 });
```

### Testing Email Service

#### Unit Tests

Integration tests for the email API are in `__tests__/api/email.test.ts`:

```bash
npm test __tests__/api/email.test.ts
```

Tests cover:
- ‚úÖ Successful sends via SES and SendGrid
- ‚úÖ Validation of required fields (to, subject, message)
- ‚úÖ Error handling and graceful failures
- ‚úÖ Password reset email flow
- ‚úÖ Appointment reminder flow
- ‚úÖ Security alert flow

#### Manual Testing with Postman

1. **Start dev server**: `npm run dev`

2. **Create new POST request** to `http://localhost:3000/api/email`

3. **Set Headers**:
   ```
   Content-Type: application/json
   ```

4. **Body (raw JSON)**:
   ```json
   {
     "to": "test@example.com",
     "subject": "Test Email",
     "message": "<h3>Hello Test!</h3>"
   }
   ```

5. **Send** and check response:
   ```json
   {
     "success": true,
     "provider": "ses",
     "messageId": "01010189b2example123"
   }
   ```

6. **Check Console Logs**:
   ```
   Email sent (SES): { to: 'test@example.com', messageId: '01010189b2example123' }
   ```

### Handling Common Issues

#### Problem: Emails Not Delivered

**Cause**: AWS SES sandbox mode or email not verified

**Solution**:
- If using SES sandbox: add recipient email to verified addresses in AWS console
- Check spam folder
- Verify sender email is correct
- Check email headers for bounces in SES dashboard

#### Problem: "Email Service Unavailable"

**Cause**: Invalid credentials or service rate limit

**Solution**:
- Verify `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` are correct
- Check AWS region is accessible
- Verify SendGrid API key is valid
- Wait 60 seconds before retrying (rate limit)

#### Problem: Slow Email Delivery

**Cause**: Synchronous API calls blocking requests

**Solution**:
- Use background tasks for bulk sends (implement Redis queue)
- Implement retry logic with exponential backoff
- Monitor CloudWatch metrics (AWS SES) or SendGrid dashboard

#### Problem: Email Headers Issues

**Cause**: Improper DKIM/SPF configuration

**Solution**:
- AWS SES: verify domain and add DKIM/SPF records to DNS
- SendGrid: verify domain under Settings ‚Üí Sender Authentication
- Test SPF/DKIM with online tools

### Sandbox vs Production

#### AWS SES Sandbox Mode

**When**: Development, testing

**Limitations**:
- Can only send to verified email addresses
- Limited to 1 email/second
- Max 200 emails/24 hours
- No reputation tracking

**Enable Production**:
1. Go to AWS SES console ‚Üí Account Dashboard
2. Click "Request Production Access"
3. Describe your use case
4. AWS reviews and grants access (usually within 24 hours)

#### SendGrid

**When**: Use free tier for development, paid for production

**Free Tier**:
- 100 emails/day
- Full API access
- Ideal for testing

**Upgrade to Paid**:
1. Add payment method in Settings ‚Üí Billing
2. No restrictions on sender emails or volume

### Rate Limits & Throttling

#### AWS SES Rate Limits (Sandbox)
- 1 email/second
- 200 emails/24 hours
- Burst capacity: 5 emails/second

**Implementation** (in `src/lib/email.ts`):
```typescript
// Add this to prevent rate limit errors
const sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));
await sleep(100); // Throttle to 10 emails/second
```

#### SendGrid Rate Limits
- Free tier: 100 emails/day
- Paid: No rate limits
- Max burst: 300 emails/10 seconds

**Implement Retry Logic**:
```typescript
async function sendEmailWithRetry(options: EmailOptions, maxAttempts = 3) {
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await sendEmail(options);
    } catch (error) {
      if (attempt === maxAttempts) throw error;
      const backoff = Math.pow(2, attempt - 1) * 1000; // exponential backoff
      await sleep(backoff);
    }
  }
}
```

### Bounce Handling & Compliance

#### AWS SES Bounce Handling

1. **Enable SNS Notifications** (AWS Console):
   - SES ‚Üí Email Addresses ‚Üí Select sender
   - Set notifications for Bounces and Complaints

2. **Webhook Handler**:
   Create `app/api/webhooks/ses-bounces/route.ts`:
   ```typescript
   export async function POST(req: Request) {
     const event = await req.json();
     
     if (event.messageType === "Bounce") {
       const bounces = event.bounce.bouncedRecipients;
       bounces.forEach((bounce: any) => {
         logger.warn(`Email bounced: ${bounce.emailAddress}`);
         // Mark user as inactive or notify admin
       });
     }
     
     if (event.messageType === "Complaint") {
       const complaints = event.complaint.complainedRecipients;
       complaints.forEach((complaint: any) => {
         logger.error(`Complaint received: ${complaint.emailAddress}`);
         // Unsubscribe user
       });
     }
     
     return NextResponse.json({ success: true });
   }
   ```

#### SendGrid Bounce Handling

1. **Enable Event Webhook**:
   - Settings ‚Üí Mail Send Settings ‚Üí Event Webhook
   - Set URL to `https://yourdomain.com/api/webhooks/sendgrid-events`

2. **Webhook Handler**:
   Create `app/api/webhooks/sendgrid-events/route.ts`:
   ```typescript
   export async function POST(req: Request) {
     const events = await req.json();
     
     events.forEach((event: any) => {
       if (event.event === "bounce") {
         logger.warn(`Email bounced: ${event.email}`);
       }
       if (event.event === "dropped") {
         logger.warn(`Email dropped: ${event.email}`);
       }
       if (event.event === "spamreport") {
         logger.error(`Spam report: ${event.email}`);
       }
     });
     
     return NextResponse.json({ success: true });
   }
   ```

### Security Best Practices

1. **Never expose API keys**: Store in `.env`, never in version control
2. **Use environment-specific senders**: Separate domains for dev/prod
3. **Validate recipient emails**: Use Zod schema validation
4. **Rate limit email sends**: Prevent email flooding attacks
5. **Monitor bounce rates**: Unsubscribe users with persistent bounces
6. **SPF/DKIM/DMARC**: Set up email authentication records
7. **Sanitize HTML content**: Use `sanitize-html` for user-generated content

### Database Integration (Future Enhancement)

Store email logs in PostgreSQL:

```sql
CREATE TABLE email_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  to VARCHAR(255) NOT NULL,
  subject TEXT NOT NULL,
  provider VARCHAR(20) NOT NULL,
  message_id VARCHAR(255),
  status VARCHAR(20) NOT NULL,
  error_message TEXT,
  created_at TIMESTAMP DEFAULT now()
);

CREATE INDEX idx_email_logs_status ON email_logs(status);
CREATE INDEX idx_email_logs_to ON email_logs(to);
```

Use Prisma schema:
```prisma
model EmailLog {
  id        String   @id @default(cuid())
  to        String
  subject   String
  provider  String
  messageId String?
  status    String
  error     String?
  createdAt DateTime @default(now())
}
```

### Key Takeaways

‚úÖ **Transactional emails** are critical for user engagement and trust

‚úÖ **Choose SES for scale**, **SendGrid for simplicity**

‚úÖ **Use templates** for consistent, branded communication

‚úÖ **Monitor bounce rates** and implement retry logic

‚úÖ **Test in sandbox mode** before production

‚úÖ **Log all sends** for audit and debugging

‚úÖ **Handle rate limits** with exponential backoff

‚úÖ **Secure API keys** in environment variables

---


